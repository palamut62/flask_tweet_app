import os
import json
import requests
from bs4 import BeautifulSoup
from fpdf import FPDF
import tweepy
from datetime import datetime, timedelta
import hashlib
from dotenv import load_dotenv
from PIL import Image
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import time
import re
from difflib import SequenceMatcher

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# Firecrawl MCP fonksiyonlarÄ± iÃ§in placeholder
def mcp_firecrawl_scrape(params):
    """Firecrawl MCP scrape fonksiyonu - Bu fonksiyon artÄ±k gerÃ§ek MCP araÃ§larÄ± kullanÄ±larak Ã§aÄŸrÄ±lacak"""
    try:
        print(f"[MCP] Firecrawl scrape Ã§aÄŸrÄ±sÄ±: {params.get('url', 'unknown')}")
        
        # Bu fonksiyon artÄ±k app.py iÃ§inde gerÃ§ek MCP araÃ§larÄ± ile Ã§aÄŸrÄ±lacak
        # Åimdilik fallback kullanÄ±lacak ama MCP entegrasyonu hazÄ±r
        return {
            "success": False,
            "reason": "MCP araÃ§larÄ± app.py seviyesinde Ã§aÄŸrÄ±lacak"
        }
        
    except Exception as e:
        print(f"[MCP] Firecrawl scrape hatasÄ±: {e}")
        return {"success": False, "error": str(e)}

HISTORY_FILE = "posted_articles.json"
HASHTAG_FILE = "hashtags.json"
ACCOUNT_FILE = "accounts.json"
SUMMARY_FILE = "summaries.json"
MCP_CONFIG_FILE = "mcp_config.json"

def fetch_latest_ai_articles_with_firecrawl():
    """Firecrawl MCP ile geliÅŸmiÅŸ haber Ã§ekme - Sadece son 4 makale"""
    try:
        # Ã–nce mevcut yayÄ±nlanan makaleleri yÃ¼kle
        posted_articles = load_json(HISTORY_FILE)
        posted_urls = [article.get('url', '') for article in posted_articles]
        posted_hashes = [article.get('hash', '') for article in posted_articles]
        
        print("ğŸ” TechCrunch AI kategorisinden Firecrawl MCP ile makale Ã§ekiliyor...")
        
        # Firecrawl MCP ile ana sayfa Ã§ek
        try:
            # Firecrawl MCP scrape fonksiyonunu kullan
            scrape_result = mcp_firecrawl_scrape({
                "url": "https://techcrunch.com/category/artificial-intelligence/",
                "formats": ["markdown", "links"],
                "onlyMainContent": True,
                "waitFor": 2000
            })
            
            if not scrape_result.get("success", False):
                print(f"âš ï¸ Firecrawl MCP hatasÄ±, fallback yÃ¶nteme geÃ§iliyor...")
                return fetch_latest_ai_articles_fallback()
            
            # Markdown iÃ§eriÄŸinden makale linklerini Ã§Ä±kar
            markdown_content = scrape_result.get("markdown", "")
            
            # Basit regex ile TechCrunch makale URL'lerini bul
            import re
            current_year = datetime.now().year
            
            # TÃ¼m TechCrunch URL'lerini bul
            all_urls = re.findall(r'https://techcrunch\.com/[^\s\)\]]+', markdown_content)
            
            # GÃ¼ncel yÄ±l ve Ã¶nceki yÄ±lÄ±n makalelerini filtrele
            article_urls = []
            for url in all_urls:
                # URL'yi temizle
                url = url.rstrip(')')
                
                # YÄ±l kontrolÃ¼
                year_check = f'/{current_year}/' in url or f'/{current_year-1}/' in url
                
                # Makale URL'si kontrolÃ¼ (tarih formatÄ± iÃ§ermeli)
                date_pattern = r'/\d{4}/\d{2}/\d{2}/'
                is_article = re.search(date_pattern, url)
                
                if (year_check and is_article and 
                    url not in posted_urls and 
                    url not in article_urls and
                    len(article_urls) < 4):  # Sadece son 4 makale
                    article_urls.append(url)
            
            print(f"ğŸ”— {len(article_urls)} makale URL'si bulundu")
            
        except Exception as firecrawl_error:
            print(f"âš ï¸ Firecrawl MCP hatasÄ±: {firecrawl_error}")
            print("ğŸ”„ Fallback yÃ¶nteme geÃ§iliyor...")
            return fetch_latest_ai_articles_fallback()
        
        articles_data = []
        for url in article_urls:
            try:
                # Her makaleyi Firecrawl MCP ile Ã§ek
                article_content = fetch_article_content_with_firecrawl(url)
                
                if article_content and len(article_content.get("content", "")) > 100:
                    title = article_content.get("title", "")
                    content = article_content.get("content", "")
                    
                    # Makale hash'i oluÅŸtur
                    article_hash = hashlib.md5(title.encode()).hexdigest()
                    
                    # Tekrar kontrolÃ¼
                    if article_hash not in posted_hashes:
                        articles_data.append({
                            "title": title,
                            "url": url,
                            "content": content,
                            "hash": article_hash,
                            "fetch_date": datetime.now().isoformat(),
                            "is_new": True,
                            "already_posted": False,
                            "source": "firecrawl_mcp"
                        })
                        print(f"ğŸ†• Firecrawl ile yeni makale: {title[:50]}...")
                    else:
                        print(f"âœ… Makale zaten paylaÅŸÄ±lmÄ±ÅŸ: {title[:50]}...")
                else:
                    print(f"âš ï¸ Ä°Ã§erik yetersiz: {url}")
                    
            except Exception as article_error:
                print(f"âŒ Makale Ã§ekme hatasÄ± ({url}): {article_error}")
                continue
        
        print(f"ğŸ“Š Firecrawl MCP ile {len(articles_data)} yeni makale bulundu")
        
        # Duplikat filtreleme uygula
        if articles_data:
            articles_data = filter_duplicate_articles(articles_data)
        
        return articles_data
        
    except Exception as e:
        print(f"Firecrawl MCP haber Ã§ekme hatasÄ±: {e}")
        print("ğŸ”„ Fallback yÃ¶nteme geÃ§iliyor...")
        return fetch_latest_ai_articles_fallback()

def fetch_latest_ai_articles():
    """Ana haber Ã§ekme fonksiyonu - Firecrawl MCP Ã¶ncelikli"""
    try:
        # Ã–nce Firecrawl MCP ile dene
        articles = fetch_latest_ai_articles_with_firecrawl()
        
        # EÄŸer Firecrawl'dan makale gelmezse fallback kullan
        if not articles:
            print("ğŸ”„ Firecrawl'dan makale gelmedi, fallback yÃ¶ntemi deneniyor...")
            articles = fetch_latest_ai_articles_fallback()
        
        return articles
        
    except Exception as e:
        print(f"Ana haber Ã§ekme hatasÄ±: {e}")
        return fetch_latest_ai_articles_fallback()

def fetch_latest_ai_articles_fallback():
    """Fallback haber Ã§ekme yÃ¶ntemi - BeautifulSoup ile"""
    try:
        # Ã–nce mevcut yayÄ±nlanan makaleleri yÃ¼kle
        posted_articles = load_json(HISTORY_FILE)
        posted_urls = [article.get('url', '') for article in posted_articles]
        posted_hashes = [article.get('hash', '') for article in posted_articles]
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        html = requests.get("https://techcrunch.com/category/artificial-intelligence/", headers=headers).text
        soup = BeautifulSoup(html, "html.parser")
        article_links = soup.select("a.loop-card__title-link")[:4]  # Sadece son 4 makale
        
        print(f"ğŸ” Fallback: TechCrunch AI kategorisinden son {len(article_links)} makale kontrol ediliyor...")
        
        articles_data = []
        for link_tag in article_links:
            title = link_tag.text.strip()
            url = link_tag['href']
            
            # Makale hash'i oluÅŸtur (baÅŸlÄ±k bazlÄ±)
            article_hash = hashlib.md5(title.encode()).hexdigest()
            
            # Tekrar kontrolÃ¼ - URL ve hash bazlÄ±
            is_already_posted = url in posted_urls or article_hash in posted_hashes
            
            if is_already_posted:
                print(f"âœ… Makale zaten paylaÅŸÄ±lmÄ±ÅŸ, atlanÄ±yor: {title[:50]}...")
                continue
            
            # Makale iÃ§eriÄŸini geliÅŸmiÅŸ ÅŸekilde Ã§ek
            content = fetch_article_content_advanced(url, headers)
            
            if content and len(content) > 100:  # Minimum iÃ§erik kontrolÃ¼
                articles_data.append({
                    "title": title, 
                    "url": url, 
                    "content": content,
                    "hash": article_hash,
                    "fetch_date": datetime.now().isoformat(),
                    "is_new": True,  # Yeni makale iÅŸareti
                    "already_posted": False,
                    "source": "fallback"
                })
                print(f"ğŸ†• Fallback ile yeni makale bulundu: {title[:50]}...")
            else:
                print(f"âš ï¸ Ä°Ã§erik yetersiz, atlanÄ±yor: {title[:50]}...")
        
        print(f"ğŸ“Š Fallback ile toplam {len(articles_data)} yeni makale bulundu")
        
        # Duplikat filtreleme uygula
        if articles_data:
            articles_data = filter_duplicate_articles(articles_data)
        
        return articles_data
        
    except Exception as e:
        print(f"Fallback haber Ã§ekme hatasÄ±: {e}")
        return []

def fetch_article_content_with_firecrawl(url):
    """Firecrawl MCP ile makale iÃ§eriÄŸi Ã§ekme"""
    try:
        print(f"ğŸ” Firecrawl MCP ile makale Ã§ekiliyor: {url[:50]}...")
        
        # Firecrawl MCP scrape fonksiyonunu kullan
        scrape_result = mcp_firecrawl_scrape({
            "url": url,
            "formats": ["markdown"],
            "onlyMainContent": True,
            "waitFor": 3000,
            "removeBase64Images": True
        })
        
        if not scrape_result.get("success", False):
            print(f"âš ï¸ Firecrawl MCP baÅŸarÄ±sÄ±z, fallback deneniyor...")
            return fetch_article_content_advanced_fallback(url)
        
        # Markdown iÃ§eriÄŸini al
        markdown_content = scrape_result.get("markdown", "")
        
        if not markdown_content or len(markdown_content) < 100:
            print(f"âš ï¸ Firecrawl'dan yetersiz iÃ§erik, fallback deneniyor...")
            return fetch_article_content_advanced_fallback(url)
        
        # BaÅŸlÄ±ÄŸÄ± Ã§Ä±kar (genellikle ilk # ile baÅŸlar)
        lines = markdown_content.split('\n')
        title = ""
        content_lines = []
        
        for line in lines:
            line = line.strip()
            if line.startswith('# ') and not title:
                title = line[2:].strip()
            elif line and not line.startswith('#') and len(line) > 20:
                content_lines.append(line)
        
        # Ä°Ã§eriÄŸi birleÅŸtir ve temizle
        content = '\n'.join(content_lines)
        
        # Gereksiz karakterleri temizle
        content = content.replace('*', '').replace('**', '').replace('_', '')
        content = ' '.join(content.split())  # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
        
        # Ä°Ã§eriÄŸi sÄ±nÄ±rla
        content = content[:2500]
        
        print(f"âœ… Firecrawl ile iÃ§erik Ã§ekildi: {len(content)} karakter")
        
        return {
            "title": title or "BaÅŸlÄ±k bulunamadÄ±",
            "content": content,
            "source": "firecrawl_mcp"
        }
        
    except Exception as e:
        print(f"âŒ Firecrawl MCP hatasÄ± ({url}): {e}")
        print("ğŸ”„ Fallback yÃ¶nteme geÃ§iliyor...")
        return fetch_article_content_advanced_fallback(url)

def fetch_article_content_advanced_fallback(url):
    """Fallback makale iÃ§eriÄŸi Ã§ekme - BeautifulSoup ile"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        article_html = requests.get(url, headers=headers, timeout=10).text
        article_soup = BeautifulSoup(article_html, "html.parser")
        
        # BaÅŸlÄ±ÄŸÄ± bul
        title = ""
        title_selectors = ["h1", "h1.entry-title", "h1.post-title", ".article-title h1"]
        for selector in title_selectors:
            title_elem = article_soup.select_one(selector)
            if title_elem:
                title = title_elem.text.strip()
                break
        
        # Ã‡oklu selector deneme - daha kapsamlÄ± iÃ§erik Ã§ekme
        content_selectors = [
            "div.article-content p",
            "div.entry-content p", 
            "div.post-content p",
            "article p",
            "div.content p",
            ".article-body p"
        ]
        
        content = ""
        for selector in content_selectors:
            paragraphs = article_soup.select(selector)
            if paragraphs:
                content = "\n".join([p.text.strip() for p in paragraphs if p.text.strip()])
                if len(content) > 200:  # Yeterli iÃ§erik bulundu
                    break
        
        # EÄŸer hala iÃ§erik bulunamadÄ±ysa, tÃ¼m p etiketlerini dene
        if not content:
            all_paragraphs = article_soup.find_all('p')
            content = "\n".join([p.text.strip() for p in all_paragraphs if len(p.text.strip()) > 50])
        
        content = content[:2000]  # Ä°Ã§eriÄŸi sÄ±nÄ±rla
        
        return {
            "title": title or "BaÅŸlÄ±k bulunamadÄ±",
            "content": content,
            "source": "fallback"
        }
        
    except Exception as e:
        print(f"Fallback makale iÃ§eriÄŸi Ã§ekme hatasÄ± ({url}): {e}")
        return None

def fetch_article_content_advanced(url, headers):
    """Geriye dÃ¶nÃ¼k uyumluluk iÃ§in eski fonksiyon"""
    result = fetch_article_content_advanced_fallback(url)
    return result.get("content", "") if result else ""

def load_json(path):
    return json.load(open(path, 'r', encoding='utf-8')) if os.path.exists(path) else []

def save_json(path, data):
    with open(path, "w", encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def summarize_article(article_content, api_key):
    """LLM ile geliÅŸmiÅŸ makale Ã¶zetleme"""
    prompt = f"""AÅŸaÄŸÄ±daki AI/teknoloji haberini TÃ¼rkÃ§e olarak Ã¶zetle. Ã–zet tweet formatÄ±nda, ilgi Ã§ekici ve bilgilendirici olsun:

Haber Ä°Ã§eriÄŸi:
{article_content[:1500]}

LÃ¼tfen:
- Maksimum 200 karakter
- Ana konuyu vurgula
- Teknik detaylarÄ± basitleÅŸtir
- Ä°lgi Ã§ekici bir dil kullan

Ã–zet:"""
    return gemini_call(prompt, api_key, max_tokens=100)

def score_article(article_content, api_key):
    prompt = f"""Bu AI/teknoloji haberinin Ã¶nemini 1-10 arasÄ±nda deÄŸerlendir (sadece sayÄ±):

{article_content[:800]}

DeÄŸerlendirme kriterleri:
- Yenilik derecesi
- SektÃ¶rel etki
- GeliÅŸtiriciler iÃ§in Ã¶nem
- Genel ilgi

Puan:"""
    result = gemini_call(prompt, api_key, max_tokens=5)
    try:
        return int(result.strip().split()[0])
    except:
        return 5

def categorize_article(article_content, api_key):
    prompt = f"""Bu haberin hedef kitlesini belirle:

{article_content[:500]}

SeÃ§enekler: Developer, Investor, General
Cevap:"""
    return gemini_call(prompt, api_key, max_tokens=10).strip()

def gemini_call(prompt, api_key, max_tokens=100):
    """Google Gemini API Ã§aÄŸrÄ±sÄ±"""
    if not api_key:
        safe_log("Gemini API anahtarÄ± bulunamadÄ±", "WARNING")
        return "API anahtarÄ± eksik"
    
    try:
        import google.generativeai as genai
        
        # API anahtarÄ±nÄ± yapÄ±landÄ±r
        genai.configure(api_key=api_key)
        
        # Modeli oluÅŸtur
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        safe_log("Gemini API Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±yor... Model: gemini-2.0-flash", "DEBUG")
        
        # Generation config
        generation_config = genai.types.GenerationConfig(
            max_output_tokens=max_tokens,
            temperature=0.7,
        )
        
        # API Ã§aÄŸrÄ±sÄ±
        response = model.generate_content(
            prompt,
            generation_config=generation_config
        )
        
        safe_log("Gemini API YanÄ±tÄ± alÄ±ndÄ±", "DEBUG")
        
        if response.text:
            content = response.text.strip()
            safe_log(f"Ä°Ã§erik alÄ±ndÄ±: {len(content)} karakter", "DEBUG")
            return content
        else:
            safe_log("Gemini API yanÄ±tÄ±nda metin bulunamadÄ±", "DEBUG")
            return "API hatasÄ±"
            
    except Exception as e:
        safe_log(f"Gemini API Ã§aÄŸrÄ± hatasÄ±: {str(e)}", "ERROR")
        return "API hatasÄ±"

def generate_smart_hashtags(title, content):
    """Makale iÃ§eriÄŸine gÃ¶re akÄ±llÄ± hashtag oluÅŸturma - 5 popÃ¼ler hashtag"""
    combined_text = f"{title.lower()} {content.lower()}"
    hashtags = []
    
    # AI ve Machine Learning hashtag'leri
    if any(keyword in combined_text for keyword in ["artificial intelligence", "ai", "machine learning", "ml", "neural", "deep learning"]):
        hashtags.extend(["#ArtificialIntelligence", "#MachineLearning", "#DeepLearning", "#NeuralNetworks"])
    
    # Teknoloji ve yazÄ±lÄ±m hashtag'leri
    if any(keyword in combined_text for keyword in ["software", "programming", "code", "developer", "api"]):
        hashtags.extend(["#SoftwareDevelopment", "#Programming", "#Developer", "#API"])
    
    # Startup ve yatÄ±rÄ±m hashtag'leri
    if any(keyword in combined_text for keyword in ["startup", "funding", "investment", "venture", "billion", "million"]):
        hashtags.extend(["#Startup", "#Investment", "#VentureCapital", "#Funding", "#Business"])
    
    # Åirket Ã¶zel hashtag'leri
    if "openai" in combined_text:
        hashtags.extend(["#OpenAI", "#ChatGPT", "#GPT"])
    if "google" in combined_text:
        hashtags.extend(["#Google", "#Alphabet", "#GoogleAI"])
    if "microsoft" in combined_text:
        hashtags.extend(["#Microsoft", "#Azure", "#Copilot"])
    if "meta" in combined_text:
        hashtags.extend(["#Meta", "#Facebook", "#MetaAI"])
    if "apple" in combined_text:
        hashtags.extend(["#Apple", "#iOS", "#AppleAI"])
    if "tesla" in combined_text:
        hashtags.extend(["#Tesla", "#ElonMusk", "#Autopilot"])
    if "nvidia" in combined_text:
        hashtags.extend(["#NVIDIA", "#GPU", "#CUDA"])
    if "anthropic" in combined_text:
        hashtags.extend(["#Anthropic", "#Claude"])
    
    # Teknoloji alanlarÄ±
    if any(keyword in combined_text for keyword in ["blockchain", "crypto", "bitcoin", "ethereum"]):
        hashtags.extend(["#Blockchain", "#Cryptocurrency", "#Web3", "#DeFi"])
    if any(keyword in combined_text for keyword in ["cloud", "aws", "azure", "gcp"]):
        hashtags.extend(["#CloudComputing", "#AWS", "#Azure", "#CloudNative"])
    if any(keyword in combined_text for keyword in ["cybersecurity", "security", "privacy", "encryption"]):
        hashtags.extend(["#Cybersecurity", "#DataPrivacy", "#InfoSec"])
    if any(keyword in combined_text for keyword in ["quantum", "quantum computing"]):
        hashtags.extend(["#QuantumComputing", "#Quantum", "#QuantumTech"])
    if any(keyword in combined_text for keyword in ["robotics", "robot", "automation"]):
        hashtags.extend(["#Robotics", "#Automation", "#RoboticProcess"])
    if any(keyword in combined_text for keyword in ["iot", "internet of things", "smart home"]):
        hashtags.extend(["#IoT", "#SmartHome", "#ConnectedDevices"])
    if any(keyword in combined_text for keyword in ["5g", "6g", "network", "connectivity"]):
        hashtags.extend(["#5G", "#Connectivity", "#Telecommunications"])
    if any(keyword in combined_text for keyword in ["ar", "vr", "augmented reality", "virtual reality", "metaverse"]):
        hashtags.extend(["#AR", "#VR", "#Metaverse", "#XR"])
    
    # Genel teknoloji hashtag'leri
    general_hashtags = ["#Innovation", "#Technology", "#DigitalTransformation", "#FutureTech", "#TechNews"]
    hashtags.extend(general_hashtags)
    
    # TekrarlarÄ± kaldÄ±r ve 5 tane seÃ§
    unique_hashtags = list(dict.fromkeys(hashtags))  # SÄ±rayÄ± koruyarak tekrarlarÄ± kaldÄ±r
    
    # En alakalÄ± 5 hashtag seÃ§
    selected_hashtags = unique_hashtags[:5]
    
    # EÄŸer 5'ten az varsa, genel hashtag'lerle tamamla
    if len(selected_hashtags) < 5:
        remaining_general = [h for h in general_hashtags if h not in selected_hashtags]
        selected_hashtags.extend(remaining_general[:5-len(selected_hashtags)])
    
    return selected_hashtags[:5]

def generate_smart_emojis(title, content):
    """Makale iÃ§eriÄŸine gÃ¶re akÄ±llÄ± emoji seÃ§imi"""
    combined_text = f"{title.lower()} {content.lower()}"
    emojis = []
    
    # Konu bazlÄ± emojiler
    if any(keyword in combined_text for keyword in ["ai", "artificial intelligence", "robot", "machine learning"]):
        emojis.extend(["ğŸ¤–", "ğŸ§ ", "âš¡"])
    if any(keyword in combined_text for keyword in ["funding", "investment", "billion", "million", "money"]):
        emojis.extend(["ğŸ’°", "ğŸ’¸", "ğŸ“ˆ"])
    if any(keyword in combined_text for keyword in ["launch", "release", "unveil", "announce"]):
        emojis.extend(["ğŸš€", "ğŸ‰", "âœ¨"])
    if any(keyword in combined_text for keyword in ["research", "development", "breakthrough", "discovery"]):
        emojis.extend(["ğŸ”¬", "ğŸ’¡", "ğŸ§ª"])
    if any(keyword in combined_text for keyword in ["security", "privacy", "protection", "safe"]):
        emojis.extend(["ğŸ”’", "ğŸ›¡ï¸", "ğŸ”"])
    if any(keyword in combined_text for keyword in ["acquisition", "merger", "partnership"]):
        emojis.extend(["ğŸ¤", "ğŸ”—", "ğŸ’¼"])
    if any(keyword in combined_text for keyword in ["search", "query", "find", "discover"]):
        emojis.extend(["ğŸ”", "ğŸ”", "ğŸ“Š"])
    if any(keyword in combined_text for keyword in ["mobile", "phone", "app", "smartphone"]):
        emojis.extend(["ğŸ“±", "ğŸ“²", "ğŸ’»"])
    if any(keyword in combined_text for keyword in ["cloud", "server", "data", "storage"]):
        emojis.extend(["â˜ï¸", "ğŸ’¾", "ğŸ—„ï¸"])
    if any(keyword in combined_text for keyword in ["game", "gaming", "entertainment"]):
        emojis.extend(["ğŸ®", "ğŸ•¹ï¸", "ğŸ¯"])
    
    # EÄŸer emoji bulunamadÄ±ysa varsayÄ±lan emojiler
    if not emojis:
        emojis = ["ğŸš€", "ğŸ’»", "ğŸŒŸ", "âš¡", "ğŸ”¥"]
    
    # En fazla 3 emoji seÃ§
    return emojis[:3]

def generate_comprehensive_analysis(article_data, api_key):
    """Makale iÃ§in kapsamlÄ± AI analizi - AyrÄ± ayrÄ± Ã§aÄŸrÄ±lar ile gÃ¼venilir sonuÃ§ (Ä°ngilizce)"""
    title = article_data.get("title", "")
    content = article_data.get("content", "")
    
    print(f"ğŸ” KapsamlÄ± AI analizi baÅŸlatÄ±lÄ±yor...")
    
    analysis_result = {
        "innovation": "",
        "companies": [],
        "impact_level": 5,
        "audience": "General",
        "hashtags": [],
        "emojis": [],
        "tweet_text": ""
    }
    
    try:
        # 1. Main innovation/insight analysis (ENGLISH)
        innovation_prompt = f"""Briefly explain the main innovation or breakthrough in this AI/tech news (max 50 words, in English):\n\nTitle: {title}\nContent: {content[:800]}\n\nMain innovation:"""
        innovation = gemini_call(innovation_prompt, api_key, max_tokens=80)
        analysis_result["innovation"] = innovation.strip() if innovation != "API hatasÄ±" else "Technology innovation"
        
        # 2. Company analysis (ENGLISH)
        company_prompt = f"""List the main companies mentioned in this news (max 3, comma separated, in English):\n\nTitle: {title}\nContent: {content[:600]}\n\nCompanies:"""
        companies_text = gemini_call(company_prompt, api_key, max_tokens=50)
        if companies_text != "API hatasÄ±":
            companies = [c.strip() for c in companies_text.split(",") if c.strip()]
            analysis_result["companies"] = companies[:3]
        
        # 3. Impact level analysis (ENGLISH)
        impact_prompt = f"""Rate the impact of this news on the tech sector from 1 to 10 (just a number):\n\nTitle: {title}\nContent: {content[:600]}\n\nImpact score (1-10):"""
        impact_text = gemini_call(impact_prompt, api_key, max_tokens=10)
        try:
            impact_level = int(impact_text.strip().split()[0])
            if 1 <= impact_level <= 10:
                analysis_result["impact_level"] = impact_level
        except:
            analysis_result["impact_level"] = 5
        
        # 4. Audience analysis (ENGLISH)
        audience_prompt = f"""Determine the target audience for this news (Developer/Investor/General):\n\nTitle: {title}\nContent: {content[:500]}\n\nAudience:"""
        audience = gemini_call(audience_prompt, api_key, max_tokens=15)
        if audience != "API hatasÄ±" and audience.strip() in ["Developer", "Investor", "General"]:
            analysis_result["audience"] = audience.strip()
        
        # 5. Hashtag analysis (ENGLISH)
        hashtag_prompt = f"""Suggest the 3 most relevant hashtags for this news (in English, only hashtags, comma separated):\n\nTitle: {title}\nContent: {content[:800]}\n\nExample: #AI, #Technology, #Innovation\n\nHashtags:"""
        ai_hashtags_text = gemini_call(hashtag_prompt, api_key, max_tokens=50)
        ai_hashtags = []
        if ai_hashtags_text != "API hatasÄ±":
            clean_text = ai_hashtags_text.replace("Hashtags:", "").replace("Hashtag'ler:", "").replace("Hashtag'ler", "").strip()
            import re
            hashtag_matches = re.findall(r'#\w+', clean_text)
            if not hashtag_matches:
                words = re.findall(r'\b[A-Za-z][A-Za-z0-9]*\b', clean_text)
                for word in words[:3]:
                    if len(word) > 2:
                        ai_hashtags.append(f"#{word}")
            else:
                ai_hashtags = hashtag_matches[:3]
        # Smart hashtag system (ENGLISH)
        smart_hashtags = generate_smart_hashtags(title, content)
        combined_hashtags = []
        for tag in ai_hashtags[:3]:
            if tag not in combined_hashtags:
                combined_hashtags.append(tag)
        for tag in smart_hashtags:
            if tag not in combined_hashtags and len(combined_hashtags) < 3:
                combined_hashtags.append(tag)
        analysis_result["hashtags"] = combined_hashtags[:3]
        # 6. Emoji analysis (unchanged, universal)
        emoji_prompt = f"""Suggest the 3 most suitable emojis for this news (just emojis, no spaces):\n\nTitle: {title}\nContent: {content[:500]}\n\nEmojis:"""
        ai_emojis_text = gemini_call(emoji_prompt, api_key, max_tokens=20)
        ai_emojis = []
        if ai_emojis_text != "API hatasÄ±":
            import re
            emoji_pattern = re.compile(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002702-\U000027B0\U000024C2-\U0001F251]+')
            found_emojis = emoji_pattern.findall(ai_emojis_text)
            for emoji in found_emojis:
                for single_emoji in emoji:
                    if single_emoji not in ai_emojis and len(ai_emojis) < 3:
                        ai_emojis.append(single_emoji)
        smart_emojis = generate_smart_emojis(title, content)
        combined_emojis = ai_emojis[:2]
        for emoji in smart_emojis:
            if emoji not in combined_emojis and len(combined_emojis) < 3:
                combined_emojis.append(emoji)
        analysis_result["emojis"] = combined_emojis[:3]
        print(f"âœ… KapsamlÄ± analiz tamamlandÄ±:")
        print(f"ğŸ”¬ Innovation: {analysis_result['innovation'][:50]}...")
        print(f"ğŸ¢ Companies: {', '.join(analysis_result['companies'])}")
        print(f"ğŸ¯ Audience: {analysis_result['audience']}")
        print(f"ğŸ·ï¸ Hashtags: {' '.join(analysis_result['hashtags'])}")
        print(f"ğŸ˜Š Emojis: {''.join(analysis_result['emojis'])}")
        return analysis_result
    except Exception as e:
        print(f"âŒ KapsamlÄ± analiz hatasÄ±: {e}")
        return {
            "innovation": "AI/tech innovation",
            "companies": [],
            "impact_level": 5,
            "audience": "General",
            "hashtags": generate_smart_hashtags(title, content)[:3],
            "emojis": generate_smart_emojis(title, content)[:3],
            "tweet_text": ""
        }

def generate_ai_tweet_with_mcp_analysis(article_data, api_key):
    """MCP verisi ile geliÅŸmiÅŸ AI tweet oluÅŸturma - KapsamlÄ± analiz ile"""
    title = article_data.get("title", "")
    content = article_data.get("content", "")
    url = article_data.get("url", "")
    source = article_data.get("source", "unknown")
    
    # Twitter karakter limiti
    TWITTER_LIMIT = 280
    URL_LENGTH = 25  # "\n\nğŸ”— " + URL kÄ±saltmasÄ± iÃ§in
    
    print(f"ğŸ¤– AI ile tweet oluÅŸturuluyor (kaynak: {source})...")
    
    try:
        # KapsamlÄ± analiz yap
        analysis = generate_comprehensive_analysis(article_data, api_key)
        
        # Tweet metni oluÅŸtur
        companies_text = ', '.join(analysis['companies'][:2]) if analysis['companies'] else ""
        
        tweet_prompt = f"""Create a compelling English tweet about this AI/tech breakthrough:

Title: {title[:120]}
Key Innovation: {analysis['innovation'][:120]}
Companies: {companies_text}

Requirements:
- Write in perfect English only
- Maximum 200 characters
- Make it clear, engaging and newsworthy
- Focus on WHAT changed and WHY it matters
- Use active voice and strong action verbs
- Include specific details when possible (numbers, capabilities)
- Make it accessible to general audience
- Sound exciting but credible
- Do NOT include hashtags, emojis, URLs, or impact levels (added separately)
- Do NOT mention impact, effect level, or rating in the tweet

Examples of good style:
- "OpenAI's new model achieves 95% accuracy in medical diagnosis"
- "Tesla's robot now performs complex assembly tasks autonomously"
- "Google's AI reduces data center energy consumption by 40%"

Tweet text:"""
        
        tweet_text = gemini_call(tweet_prompt, api_key, max_tokens=80)
        
        if tweet_text == "API hatasÄ±" or not tweet_text.strip():
            # Fallback tweet metni - daha anlamlÄ±
            if analysis['companies'] and analysis['innovation']:
                company = analysis['companies'][0]
                innovation = analysis['innovation'][:100]
                # Daha anlamlÄ± fallback tweet oluÅŸtur
                if "launch" in innovation.lower():
                    tweet_text = f"{company} launches {innovation.lower().replace('launch', '').strip()}"
                elif "announce" in innovation.lower():
                    tweet_text = f"{company} announces {innovation.lower().replace('announce', '').strip()}"
                elif "develop" in innovation.lower():
                    tweet_text = f"{company} develops {innovation.lower().replace('develop', '').strip()}"
                else:
                    tweet_text = f"{company} unveils {innovation}"
            elif analysis['innovation']:
                tweet_text = f"Breaking: {analysis['innovation'][:150]}"
            else:
                tweet_text = f"AI breakthrough: {title[:120]}"
        
        # Tweet metnini temizle
        tweet_text = tweet_text.replace("Tweet:", "").replace("Tweet metni:", "").strip()
        
        # Gereksiz karakterleri temizle
        tweet_text = tweet_text.replace('"', '').replace("'", "'").strip()
        
        # Impact/etki bilgilerini temizle
        import re
        # "impact: orta", "etki: yÃ¼ksek", "effect: medium" gibi ifadeleri kaldÄ±r
        tweet_text = re.sub(r'\b(impact|etki|effect)\s*:\s*\w+\b', '', tweet_text, flags=re.IGNORECASE)
        # "(impact: medium)", "[etki: yÃ¼ksek]" gibi parantez iÃ§indeki ifadeleri kaldÄ±r
        tweet_text = re.sub(r'[\(\[\{]\s*(impact|etki|effect)\s*:\s*\w+\s*[\)\]\}]', '', tweet_text, flags=re.IGNORECASE)
        # Fazla boÅŸluklarÄ± temizle
        tweet_text = re.sub(r'\s+', ' ', tweet_text).strip()
        
        # Hashtag ve emoji metinlerini oluÅŸtur
        hashtag_text = " ".join(analysis['hashtags']).strip()
        emoji_text = "".join(analysis['emojis']).strip()
        url_part = f"\n\nğŸ”— {url}"
        
        # Sabit kÄ±sÄ±mlarÄ±n uzunluÄŸu
        fixed_parts_length = len(emoji_text) + len(hashtag_text) + len(url_part) + 2  # 2 boÅŸluk iÃ§in
        available_chars = TWITTER_LIMIT - fixed_parts_length
        
        # Tweet metnini temizle ve kÄ±salt
        tweet_text = tweet_text.strip()
        
        # EÄŸer tweet metni Ã§ok uzunsa kÄ±salt
        if len(tweet_text) > available_chars:
            # "..." iÃ§in 3 karakter ayÄ±r
            tweet_text = tweet_text[:available_chars-3] + "..."
        
        # Final tweet oluÅŸtur - boÅŸluklarÄ± optimize et
        if emoji_text and tweet_text:
            # Emoji varsa emoji ile tweet arasÄ±nda tek boÅŸluk
            main_content = f"{emoji_text} {tweet_text}"
        else:
            # Emoji yoksa direkt tweet
            main_content = tweet_text
        
        if hashtag_text:
            # Hashtag varsa tek boÅŸluk ile ekle
            final_tweet = f"{main_content} {hashtag_text}{url_part}"
        else:
            # Hashtag yoksa direkt URL ekle
            final_tweet = f"{main_content}{url_part}"
        
        # Son gÃ¼venlik kontrolÃ¼ - eÄŸer hala uzunsa daha agresif kÄ±salt
        if len(final_tweet) > TWITTER_LIMIT:
            excess = len(final_tweet) - TWITTER_LIMIT
            # Tweet metninden fazlalÄ±ÄŸÄ± Ã§Ä±kar
            new_tweet_length = len(tweet_text) - excess - 3  # 3 "..." iÃ§in
            if new_tweet_length > 10:  # Minimum 10 karakter bÄ±rak
                tweet_text = tweet_text[:new_tweet_length] + "..."
            else:
                # Ã‡ok kÄ±sa kalÄ±rsa hashtag'leri azalt
                hashtag_text = " ".join(analysis['hashtags'][:2])  # 2 hashtag
                fixed_parts_length = len(emoji_text) + len(hashtag_text) + len(url_part) + 1  # 1 boÅŸluk
                available_chars = TWITTER_LIMIT - fixed_parts_length
                tweet_text = tweet_text[:available_chars-3] + "..."
            
            # Yeniden oluÅŸtur
            if emoji_text and tweet_text:
                main_content = f"{emoji_text} {tweet_text}"
            else:
                main_content = tweet_text
            
            if hashtag_text:
                final_tweet = f"{main_content} {hashtag_text}{url_part}"
            else:
                final_tweet = f"{main_content}{url_part}"
        
        print(f"âœ… AI analizi ile tweet oluÅŸturuldu: {len(final_tweet)} karakter")
        print(f"ğŸ“ Tweet metni: {len(tweet_text)} karakter")
        print(f"ğŸ·ï¸ AI Hashtag'ler: {hashtag_text} ({len(hashtag_text)} karakter)")
        print(f"ğŸ˜Š AI Emojiler: {emoji_text} ({len(emoji_text)} karakter)")
        print(f"ğŸ”— URL kÄ±smÄ±: {len(url_part)} karakter")
        print(f"ğŸ¯ Hedef Kitle: {analysis['audience']}")
        
        # Dictionary formatÄ±nda dÃ¶ndÃ¼r
        return {
            "tweet": final_tweet,
            "impact_score": 8,  # VarsayÄ±lan yÃ¼ksek skor
            "analysis": analysis,
            "source": "mcp_analysis"
        }
        
    except Exception as e:
        print(f"âŒ AI tweet oluÅŸturma hatasÄ±: {e}")
        print("ğŸ”„ Fallback yÃ¶nteme geÃ§iliyor...")
        fallback_tweet = generate_ai_tweet_with_content_fallback(article_data, api_key)
        return {
            "tweet": fallback_tweet,
            "impact_score": 6,  # Orta skor
            "analysis": {"audience": "General", "companies": [], "hashtags": [], "emojis": []},
            "source": "fallback"
        }

def generate_ai_tweet_with_content(article_data, api_key):
    """Ana tweet oluÅŸturma fonksiyonu - MCP analizi Ã¶ncelikli"""
    try:
        # Ã–nce MCP analizi ile dene
        tweet_data = generate_ai_tweet_with_mcp_analysis(article_data, api_key)
        
        # EÄŸer baÅŸarÄ±sÄ±zsa fallback kullan
        if not tweet_data or not tweet_data.get('tweet') or len(tweet_data.get('tweet', '')) < 50:
            print("ğŸ”„ MCP analizi yetersiz, fallback yÃ¶ntemi deneniyor...")
            fallback_tweet = generate_ai_tweet_with_content_fallback(article_data, api_key)
            return {
                "tweet": fallback_tweet,
                "impact_score": 6,
                "analysis": {"audience": "General", "companies": [], "hashtags": [], "emojis": []},
                "source": "fallback"
            }
        
        return tweet_data
        
    except Exception as e:
        print(f"Ana tweet oluÅŸturma hatasÄ±: {e}")
        fallback_tweet = generate_ai_tweet_with_content_fallback(article_data, api_key)
        return {
            "tweet": fallback_tweet,
            "impact_score": 6,
            "analysis": {"audience": "General", "companies": [], "hashtags": [], "emojis": []},
            "source": "fallback"
        }

def generate_ai_tweet_with_content_fallback(article_data, api_key):
    """Fallback tweet oluÅŸturma - Eski yÃ¶ntem"""
    title = article_data.get("title", "")
    content = article_data.get("content", "")
    url = article_data.get("url", "")
    
    # Twitter karakter limiti (URL iÃ§in 23 karakter ayrÄ±lÄ±r)
    TWITTER_LIMIT = 280
    URL_LENGTH = 25  # "\n\nğŸ”— " + URL kÄ±saltmasÄ± iÃ§in
    
    # AkÄ±llÄ± hashtag ve emoji oluÅŸtur
    smart_hashtags = generate_smart_hashtags(title, content)
    smart_emojis = generate_smart_emojis(title, content)
    
    hashtag_text = " ".join(smart_hashtags).strip()
    emoji_text = "".join(smart_emojis).strip()
    
    # Hashtag ve emoji iÃ§in yer ayÄ±r
    hashtag_emoji_length = len(hashtag_text) + len(emoji_text) + 2  # 2 boÅŸluk iÃ§in
    MAX_CONTENT_LENGTH = TWITTER_LIMIT - URL_LENGTH - hashtag_emoji_length
    
    # Ä°ngilizce tweet iÃ§in geliÅŸmiÅŸ prompt
    prompt = f"""Create a compelling English tweet about this AI/tech breakthrough:

Article Title: {title}
Article Content: {content[:1000]}

Requirements:
- Write in perfect English only
- Maximum {MAX_CONTENT_LENGTH} characters
- Make it clear, engaging and newsworthy
- Focus on WHAT changed and WHY it matters
- Use active voice and strong action verbs
- Include specific details when possible (numbers, capabilities, improvements)
- Make it accessible to general audience
- Sound exciting but credible
- Avoid jargon and technical terms
- Do NOT include hashtags, emojis, URLs, or impact levels (added separately)
- Do NOT mention impact, effect level, or rating in the tweet

Examples of good style:
- "OpenAI's new model achieves 95% accuracy in medical diagnosis"
- "Tesla's robot now performs complex assembly tasks autonomously"
- "Google's AI reduces data center energy consumption by 40%"
- "Meta's VR headset delivers 4K resolution at half the price"

Tweet text (max {MAX_CONTENT_LENGTH} chars):"""

    try:
        tweet_text = gemini_call(prompt, api_key, max_tokens=150)
        
        if tweet_text and len(tweet_text.strip()) > 10:
            # Tweet metnini temizle
            import re
            # Impact/etki bilgilerini temizle
            tweet_text = re.sub(r'\b(impact|etki|effect)\s*:\s*\w+\b', '', tweet_text, flags=re.IGNORECASE)
            tweet_text = re.sub(r'[\(\[\{]\s*(impact|etki|effect)\s*:\s*\w+\s*[\)\]\}]', '', tweet_text, flags=re.IGNORECASE)
            tweet_text = re.sub(r'\s+', ' ', tweet_text).strip()
            
            # Karakter limiti kontrolÃ¼
            if len(tweet_text.strip()) > MAX_CONTENT_LENGTH:
                tweet_text = tweet_text.strip()[:MAX_CONTENT_LENGTH-3] + "..."
            
            # Emoji, tweet metni, hashtag'ler ve URL'yi birleÅŸtir - boÅŸluklarÄ± optimize et
            parts = []
            if emoji_text:
                parts.append(emoji_text)
            if tweet_text.strip():
                parts.append(tweet_text.strip())
            if hashtag_text:
                parts.append(hashtag_text)
            
            main_content = " ".join(parts)
            final_tweet = f"{main_content}\n\nğŸ”— {url}"
            
            # Final karakter kontrolÃ¼
            if len(final_tweet) > TWITTER_LIMIT:
                # Tekrar kÄ±salt
                excess = len(final_tweet) - TWITTER_LIMIT
                tweet_text = tweet_text.strip()[:-(excess + 3)] + "..."
                
                # Yeniden birleÅŸtir - boÅŸluklarÄ± optimize et
                parts = []
                if emoji_text:
                    parts.append(emoji_text)
                if tweet_text:
                    parts.append(tweet_text)
                if hashtag_text:
                    parts.append(hashtag_text)
                
                main_content = " ".join(parts)
                final_tweet = f"{main_content}\n\nğŸ”— {url}"
            
            print(f"[FALLBACK] Tweet oluÅŸturuldu: {len(final_tweet)} karakter (limit: {TWITTER_LIMIT})")
            print(f"[FALLBACK] Hashtag'ler: {hashtag_text}")
            print(f"[FALLBACK] Emojiler: {emoji_text}")
            
            return final_tweet
        else:
            print("[FALLBACK] API yanÄ±tÄ± yetersiz, basit fallback tweet oluÅŸturuluyor...")
            return create_fallback_tweet(title, content, url)
            
    except Exception as e:
        print(f"Fallback tweet oluÅŸturma hatasÄ±: {e}")
        print("[FALLBACK] API hatasÄ±, basit fallback tweet oluÅŸturuluyor...")
        return create_fallback_tweet(title, content, url)

def create_fallback_tweet(title, content, url=""):
    """API hatasÄ± durumunda fallback tweet oluÅŸtur - AkÄ±llÄ± hashtag ve emoji ile"""
    try:
        # Twitter karakter limiti
        TWITTER_LIMIT = 280
        URL_LENGTH = 25  # "\n\nğŸ”— " + URL iÃ§in
        
        # AkÄ±llÄ± hashtag ve emoji oluÅŸtur
        smart_hashtags = generate_smart_hashtags(title, content)
        smart_emojis = generate_smart_emojis(title, content)
        
        hashtag_text = " ".join(smart_hashtags).strip()
        emoji_text = "".join(smart_emojis).strip()
        
        # Hashtag ve emoji iÃ§in yer ayÄ±r
        hashtag_emoji_length = len(hashtag_text) + len(emoji_text) + 2  # 2 boÅŸluk iÃ§in
        MAX_CONTENT_LENGTH = TWITTER_LIMIT - URL_LENGTH - hashtag_emoji_length
        
        # BaÅŸlÄ±ÄŸÄ± temizle
        clean_title = title.strip()
        
        # Ä°Ã§erikten anahtar kelimeler ve Ã¶nemli bilgiler Ã§Ä±kar
        content_lower = content.lower()
        title_lower = title.lower()
        combined_text = f"{title_lower} {content_lower}"
        
        # SayÄ±sal bilgileri Ã§Ä±kar
        import re
        numbers = re.findall(r'\$?(\d+(?:\.\d+)?)\s*(billion|million|%|percent)', combined_text, re.IGNORECASE)
        
        # Åirket isimlerini tespit et
        companies = []
        company_names = ["OpenAI", "Google", "Microsoft", "Meta", "Apple", "Amazon", "Tesla", "Nvidia", "Anthropic", "Perplexity", "Cursor", "DeviantArt", "AMD", "Intel"]
        for company in company_names:
            if company.lower() in combined_text:
                companies.append(company)
        
        # Ana tweet metni oluÅŸtur - daha anlamlÄ± Ä°ngilizce
        tweet_parts = []
        
        # Åirket ve eylem bazlÄ± tweet oluÅŸtur
        if companies:
            main_company = companies[0]
            
            # Eyleme gÃ¶re anlamlÄ± cÃ¼mle oluÅŸtur
            if "acquisition" in combined_text or "acquire" in combined_text:
                if "billion" in combined_text:
                    tweet_parts.append(f"{main_company} completes major acquisition")
                else:
                    tweet_parts.append(f"{main_company} acquires strategic company")
            elif "funding" in combined_text or "investment" in combined_text:
                if numbers:
                    largest_num = max(numbers, key=lambda x: float(x[0]))
                    if largest_num[1].lower() == 'billion':
                        tweet_parts.append(f"{main_company} raises ${largest_num[0]}B in funding")
                    elif largest_num[1].lower() == 'million':
                        tweet_parts.append(f"{main_company} secures ${largest_num[0]}M investment")
                    else:
                        tweet_parts.append(f"{main_company} secures major funding")
                else:
                    tweet_parts.append(f"{main_company} secures new funding round")
            elif "launch" in combined_text or "release" in combined_text:
                if "ai" in combined_text or "artificial intelligence" in combined_text:
                    tweet_parts.append(f"{main_company} launches new AI technology")
                elif "robot" in combined_text:
                    tweet_parts.append(f"{main_company} unveils advanced robotics")
                else:
                    tweet_parts.append(f"{main_company} releases breakthrough innovation")
            elif "partnership" in combined_text or "partner" in combined_text:
                tweet_parts.append(f"{main_company} forms strategic partnership")
            elif "breakthrough" in combined_text or "innovation" in combined_text:
                tweet_parts.append(f"{main_company} achieves major breakthrough")
            else:
                # BaÅŸlÄ±ÄŸÄ± kullan ama ÅŸirket adÄ±nÄ± Ã¶ne Ã§Ä±kar
                clean_title_short = clean_title.replace(main_company, "").strip()
                if clean_title_short:
                    tweet_parts.append(f"{main_company}: {clean_title_short[:80]}")
                else:
                    tweet_parts.append(f"{main_company} makes major announcement")
        else:
            # Åirket yoksa baÅŸlÄ±ÄŸÄ± kullan
            if "ai" in combined_text or "artificial intelligence" in combined_text:
                tweet_parts.append(f"AI breakthrough: {clean_title[:100]}")
            elif "robot" in combined_text:
                tweet_parts.append(f"Robotics advance: {clean_title[:100]}")
            else:
                tweet_parts.append(f"Tech news: {clean_title[:120]}")
        
        # SayÄ±sal bilgi ekle (eÄŸer henÃ¼z eklenmemiÅŸse)
        if numbers and not any("$" in part for part in tweet_parts):
            largest_num = max(numbers, key=lambda x: float(x[0]))
            if largest_num[1].lower() == 'billion':
                tweet_parts.append(f"(${largest_num[0]}B)")
            elif largest_num[1].lower() == 'million':
                tweet_parts.append(f"({largest_num[0]}M)")
            elif largest_num[1].lower() in ['%', 'percent']:
                tweet_parts.append(f"({largest_num[0]}% improvement)")
        
        # Tweet'i birleÅŸtir
        main_text = " ".join(tweet_parts)
        
        # Karakter limiti kontrolÃ¼
        if len(main_text) > MAX_CONTENT_LENGTH:
            # Ã‡ok uzunsa kÄ±salt
            main_text = main_text[:MAX_CONTENT_LENGTH-3] + "..."
        
        # Emoji, tweet metni, hashtag'ler ve URL'yi birleÅŸtir
        if url:
            fallback_tweet = f"{emoji_text} {main_text} {hashtag_text}\n\nğŸ”— {url}"
        else:
            fallback_tweet = f"{emoji_text} {main_text} {hashtag_text}"
        
        # Final karakter kontrolÃ¼
        if len(fallback_tweet) > TWITTER_LIMIT:
            # Tekrar kÄ±salt
            excess = len(fallback_tweet) - TWITTER_LIMIT
            main_text = main_text[:-(excess + 3)] + "..."
            if url:
                fallback_tweet = f"{emoji_text} {main_text} {hashtag_text}\n\nğŸ”— {url}"
            else:
                fallback_tweet = f"{emoji_text} {main_text} {hashtag_text}"
        
        print(f"[FALLBACK] Tweet oluÅŸturuldu: {len(fallback_tweet)} karakter (limit: {TWITTER_LIMIT})")
        print(f"[FALLBACK] Hashtag'ler: {hashtag_text}")
        print(f"[FALLBACK] Emojiler: {emoji_text}")
        
        return fallback_tweet
        
    except Exception as e:
        print(f"Fallback tweet oluÅŸturma hatasÄ±: {e}")
        # En basit fallback - akÄ±llÄ± hashtag ve emoji ile
        try:
            simple_hashtags = generate_smart_hashtags(title, "")[:3]  # 3 hashtag
            simple_emojis = generate_smart_emojis(title, "")[:2]  # 2 emoji
            
            hashtag_text = " ".join(simple_hashtags)
            emoji_text = "".join(simple_emojis)
            
            # Karakter hesaplama
            url_length = len(f"\n\nğŸ”— {url}") if url else 0
            available_chars = TWITTER_LIMIT - url_length - len(hashtag_text) - len(emoji_text) - 2
            
            # BaÅŸlÄ±ÄŸÄ± kÄ±salt
            if len(title) > available_chars:
                title_text = title[:available_chars-3] + "..."
            else:
                title_text = title
            
            simple_tweet = f"{emoji_text} {title_text} {hashtag_text}"
            if url:
                simple_tweet += f"\n\nğŸ”— {url}"
            
            return simple_tweet
            
        except:
            # En son Ã§are - basit tweet
            simple_text = f"ğŸ¤– {title[:200]}... #AI #Innovation #Technology"
            if url:
                simple_tweet = f"{simple_text}\n\nğŸ”— {url}"
            else:
                simple_tweet = simple_text
            
            # Karakter limiti kontrolÃ¼
            if len(simple_tweet) > TWITTER_LIMIT:
                available = TWITTER_LIMIT - len("\n\nğŸ”— ") - len(url) - len(" #AI #Innovation #Technology") - 3
                simple_text = f"ğŸ¤– {title[:available]}... #AI #Innovation #Technology"
                simple_tweet = f"{simple_text}\n\nğŸ”— {url}" if url else simple_text
            
            return simple_tweet

def setup_twitter_api():
    import tweepy
    import os
    # V1.1 API ile oturum aÃ§
    auth = tweepy.OAuth1UserHandler(
        os.environ['TWITTER_API_KEY'],
        os.environ['TWITTER_API_SECRET'],
        os.environ['TWITTER_ACCESS_TOKEN'],
        os.environ['TWITTER_ACCESS_TOKEN_SECRET']
    )
    api = tweepy.API(auth)
    return api

def post_tweet(tweet_text, article_title=""):
    """X platformunda tweet paylaÅŸma ve Gmail bildirimi - Twitter API v2 kullanarak"""
    try:
        # Twitter API v2 kullan
        tweet_result = post_text_tweet_v2(tweet_text)
        
        # BaÅŸarÄ±sÄ±z olursa hata dÃ¶ndÃ¼r
        if not tweet_result.get("success"):
            safe_log(f"Tweet paylaÅŸÄ±m hatasÄ±: {tweet_result.get('error', 'Bilinmeyen hata')}", "ERROR")
            return tweet_result
        
        tweet_id = tweet_result.get("tweet_id")
        tweet_url = tweet_result.get("url")
        
        # Gmail bildirimi gÃ¶nder (Telegram yerine)
        email_sent = False
        try:
            gmail_result = send_gmail_notification(
                message=tweet_text,
                tweet_url=tweet_url,
                article_title=article_title
            )
            if gmail_result.get("success"):
                safe_log(f"Gmail bildirimi gÃ¶nderildi: {gmail_result.get('email')}", "INFO")
                email_sent = True
            else:
                safe_log(f"Gmail bildirimi gÃ¶nderilemedi: {gmail_result.get('reason', 'unknown')}", "WARNING")
        except Exception as gmail_error:
            safe_log(f"Gmail bildirim hatasÄ±: {gmail_error}", "ERROR")
        
        # Fallback: Telegram bildirimi (eÄŸer Gmail baÅŸarÄ±sÄ±z olursa)
        telegram_sent = False
        if not email_sent:
            try:
                telegram_result = send_telegram_notification(
                    message=tweet_text,
                    tweet_url=tweet_url,
                    article_title=article_title
                )
                if telegram_result.get("success"):
                    safe_log("Fallback Telegram bildirimi gÃ¶nderildi", "INFO")
                    telegram_sent = True
                else:
                    safe_log(f"Fallback Telegram bildirimi de baÅŸarÄ±sÄ±z: {telegram_result.get('reason', 'unknown')}", "WARNING")
            except Exception as telegram_error:
                safe_log(f"Fallback Telegram bildirim hatasÄ±: {telegram_error}", "ERROR")
        
        return {
            "success": True,
            "tweet_id": tweet_id,
            "url": tweet_url,
            "email_sent": email_sent,
            "telegram_sent": telegram_sent
        }
        
    except Exception as e:
        safe_log(f"Tweet paylaÅŸÄ±m hatasÄ±: {str(e)}", "ERROR")
        return {"success": False, "error": f"Tweet paylaÅŸÄ±m hatasÄ±: {str(e)}"}

def mark_article_as_posted(article_data, tweet_result):
    """Makaleyi paylaÅŸÄ±ldÄ± olarak iÅŸaretle - API ve manuel paylaÅŸÄ±mlarÄ± destekler"""
    try:
        posted_articles = load_json(HISTORY_FILE)
        
        # Manuel paylaÅŸÄ±m kontrolÃ¼
        is_manual_post = tweet_result.get("manual_post", False)
        
        posted_article = {
            "title": article_data.get("title", ""),
            "url": article_data.get("url", ""),
            "hash": article_data.get("hash", ""),
            "posted_date": datetime.now().isoformat(),
            "tweet_id": tweet_result.get("tweet_id", ""),
            "tweet_url": tweet_result.get("url", ""),
            "manual_post": is_manual_post,
            "post_method": "manuel" if is_manual_post else "api"
        }
        
        # Manuel paylaÅŸÄ±m iÃ§in ek bilgiler
        if is_manual_post:
            posted_article["tweet_text"] = article_data.get("tweet_text", "")
            posted_article["manual_posted_at"] = tweet_result.get("posted_at", datetime.now().isoformat())
        
        posted_articles.append(posted_article)
        save_json(HISTORY_FILE, posted_articles)
        
        safe_log(f"Makale kaydedildi: {article_data.get('title', '')[:50]}... (YÃ¶ntem: {posted_article['post_method']})", "INFO")
        
        return True
    except Exception as e:
        safe_log(f"Makale kaydetme hatasÄ±: {e}", "ERROR")
        return False

def check_duplicate_articles():
    """Tekrarlanan makaleleri temizle"""
    try:
        posted_articles = load_json(HISTORY_FILE)
        
        # Son 30 gÃ¼nlÃ¼k makaleleri tut
        cutoff_date = datetime.now() - timedelta(days=30)
        
        filtered_articles = []
        seen_hashes = set()
        
        for article in posted_articles:
            try:
                posted_date = datetime.fromisoformat(article.get("posted_date", ""))
                article_hash = article.get("hash", "")
                
                if posted_date > cutoff_date and article_hash not in seen_hashes:
                    filtered_articles.append(article)
                    seen_hashes.add(article_hash)
            except:
                continue
        
        save_json(HISTORY_FILE, filtered_articles)
        return len(posted_articles) - len(filtered_articles)
        
    except Exception as e:
        print(f"Tekrar temizleme hatasÄ±: {e}")
        return 0

def generate_ai_digest(summaries_with_links, api_key):
    """Eski fonksiyon - geriye dÃ¶nÃ¼k uyumluluk iÃ§in"""
    if not summaries_with_links:
        return "Ã–zet bulunamadÄ±"
    
    # Ä°lk makaleyi kullanarak tweet oluÅŸtur
    first_summary = summaries_with_links[0]
    article_data = {
        "title": "AI Digest",
        "content": first_summary.get("summary", ""),
        "url": first_summary.get("url", "")
    }
    
    return generate_ai_tweet_with_content(article_data, api_key)

def create_pdf(summaries, filename="daily_digest.pdf"):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="AI Tweet Digest", ln=True, align='C')
    for s in summaries:
        pdf.multi_cell(0, 10, f"â€¢ {s}")
    pdf.output(filename)
    return filename

def get_posted_articles_summary():
    """PaylaÅŸÄ±lmÄ±ÅŸ makalelerin Ã¶zetini dÃ¶ndÃ¼r - geliÅŸmiÅŸ istatistiklerle"""
    try:
        from datetime import datetime, date, timedelta
        posted_articles = load_json(HISTORY_FILE)
        today = date.today()
        
        # Son 7 gÃ¼nlÃ¼k makaleleri al
        cutoff_date = datetime.now() - timedelta(days=7)
        recent_articles = []
        today_articles = []
        week_articles = []
        
        # En yÃ¼ksek skorlu makale
        highest_scored = None
        highest_score = 0
        
        # En son paylaÅŸÄ±lan makale
        latest_posted = None
        latest_date = None
        
        for article in posted_articles:
            try:
                posted_date_str = article.get("posted_date", "")
                if posted_date_str:
                    posted_date = datetime.fromisoformat(posted_date_str.replace('Z', '+00:00'))
                    
                    # BugÃ¼nkÃ¼ makaleler
                    if posted_date.date() == today:
                        today_articles.append(article)
                    
                    # Son 7 gÃ¼nlÃ¼k makaleler
                    if posted_date > cutoff_date:
                        recent_articles.append(article)
                        week_articles.append(article)
                    
                    # En son paylaÅŸÄ±lan
                    if latest_date is None or posted_date > latest_date:
                        latest_date = posted_date
                        latest_posted = article
                
                # En yÃ¼ksek skorlu makale (eÄŸer skor varsa)
                score = article.get("score", 0)
                if isinstance(score, (int, float)) and score > highest_score:
                    highest_score = score
                    highest_scored = article
                    
            except Exception as e:
                print(f"[DEBUG] Makale parse hatasÄ±: {e}")
                continue
        
        # BaÅŸarÄ± oranÄ± hesapla (basit: paylaÅŸÄ±lan / toplam)
        success_rate = (len(posted_articles) / max(len(posted_articles) + 1, 1)) * 100
        
        # Kategori daÄŸÄ±lÄ±mÄ± (eÄŸer varsa)
        category_distribution = {}
        for article in posted_articles:
            category = article.get("category", "Genel")
            category_distribution[category] = category_distribution.get(category, 0) + 1
        
        return {
            "total_posted": len(posted_articles),
            "recent_posted": len(recent_articles),
            "recent_articles": recent_articles[-5:],  # Son 5 makale
            "today_articles": len(today_articles),
            "week_articles": len(week_articles),
            "highest_scored": highest_scored,
            "latest_posted": latest_posted,
            "success_rate": success_rate,
            "category_distribution": category_distribution,
            "average_score": highest_score / max(len(posted_articles), 1) if highest_score > 0 else 0,
            "last_check_time": datetime.now().strftime("%H:%M") if posted_articles else "HenÃ¼z yok"
        }
        
    except Exception as e:
        print(f"PaylaÅŸÄ±lmÄ±ÅŸ makale Ã¶zeti hatasÄ±: {e}")
        return {
            "total_posted": 0, 
            "recent_posted": 0, 
            "recent_articles": [],
            "today_articles": 0,
            "week_articles": 0,
            "highest_scored": None,
            "latest_posted": None,
            "success_rate": 0,
            "category_distribution": {},
            "average_score": 0,
            "last_check_time": "HenÃ¼z yok"
        }

def reset_all_data():
    """TÃ¼m uygulama verilerini sÄ±fÄ±rla"""
    try:
        files_to_reset = [
            "posted_articles.json",
            "pending_tweets.json", 
            "summaries.json",
            "hashtags.json",
            "accounts.json"
        ]
        
        reset_count = 0
        for file_path in files_to_reset:
            if os.path.exists(file_path):
                save_json(file_path, [])
                reset_count += 1
                print(f"âœ… {file_path} sÄ±fÄ±rlandÄ±")
            else:
                # Dosya yoksa boÅŸ oluÅŸtur
                save_json(file_path, [])
                print(f"ğŸ†• {file_path} oluÅŸturuldu")
        
        return {
            "success": True,
            "message": f"âœ… {reset_count} dosya sÄ±fÄ±rlandÄ±",
            "reset_files": files_to_reset
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ SÄ±fÄ±rlama hatasÄ±: {str(e)}",
            "reset_files": []
        }

def clear_pending_tweets():
    """Sadece bekleyen tweet'leri temizle"""
    try:
        pending_tweets = load_json("pending_tweets.json")
        
        # Sadece posted olanlarÄ± tut, pending olanlarÄ± sil
        posted_tweets = [t for t in pending_tweets if t.get("status") == "posted"]
        
        save_json("pending_tweets.json", posted_tweets)
        
        cleared_count = len(pending_tweets) - len(posted_tweets)
        
        return {
            "success": True,
            "message": f"âœ… {cleared_count} bekleyen tweet temizlendi",
            "cleared_count": cleared_count
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ Temizleme hatasÄ±: {str(e)}",
            "cleared_count": 0
        }

def get_data_statistics():
    """Veri istatistiklerini dÃ¶ndÃ¼r - bugÃ¼nkÃ¼ analizler dahil"""
    try:
        from datetime import datetime, date
        today = date.today()
        stats = {}
        
        # PaylaÅŸÄ±lan makaleler
        posted_articles = load_json("posted_articles.json")
        stats["posted_articles"] = len(posted_articles)
        stats["total_articles"] = len(posted_articles)  # Template uyumluluÄŸu iÃ§in
        
        # BugÃ¼nkÃ¼ paylaÅŸÄ±lan makaleler
        today_articles = []
        for article in posted_articles:
            if article.get("posted_date"):
                try:
                    # ISO format tarihini parse et
                    posted_date = datetime.fromisoformat(article["posted_date"].replace('Z', '+00:00'))
                    if posted_date.date() == today:
                        today_articles.append(article)
                except (ValueError, TypeError) as e:
                    print(f"[DEBUG] Tarih parse hatasÄ±: {e} - {article.get('posted_date')}")
                    continue
        
        stats["today_articles"] = len(today_articles)
        
        # Bekleyen tweet'ler
        pending_tweets = load_json("pending_tweets.json")
        pending_count = len([t for t in pending_tweets if t.get("status") == "pending"])
        posted_count = len([t for t in pending_tweets if t.get("status") == "posted"])
        stats["pending_tweets"] = pending_count
        stats["posted_tweets_in_pending"] = posted_count
        
        # BugÃ¼nkÃ¼ bekleyen tweet'ler
        today_pending = []
        for tweet in pending_tweets:
            if tweet.get("created_date"):
                try:
                    created_date = datetime.fromisoformat(tweet["created_date"].replace('Z', '+00:00'))
                    if created_date.date() == today and tweet.get("status") == "pending":
                        today_pending.append(tweet)
                except (ValueError, TypeError):
                    continue
        
        stats["today_pending"] = len(today_pending)
        
        # Ã–zetler
        summaries = load_json("summaries.json")
        stats["summaries"] = len(summaries)
        
        # Hashtag'ler
        hashtags = load_json("hashtags.json")
        stats["hashtags"] = len(hashtags)
        
        # Hesaplar
        accounts = load_json("accounts.json")
        stats["accounts"] = len(accounts)
        
        # BugÃ¼nkÃ¼ toplam aktivite
        stats["today_total_activity"] = stats["today_articles"] + stats["today_pending"]
        
        print(f"[DEBUG] Ä°statistikler: BugÃ¼n {stats['today_articles']} makale, {stats['today_pending']} bekleyen")
        
        return stats
        
    except Exception as e:
        print(f"Ä°statistik hatasÄ±: {e}")
        return {
            "posted_articles": 0,
            "total_articles": 0,
            "today_articles": 0,
            "pending_tweets": 0,
            "today_pending": 0,
            "posted_tweets_in_pending": 0,
            "summaries": 0,
            "hashtags": 0,
            "accounts": 0,
            "today_total_activity": 0
        }

def load_automation_settings():
    """OtomatikleÅŸtirme ayarlarÄ±nÄ± yÃ¼kle"""
    try:
        settings_data = load_json("automation_settings.json")
        
        # EÄŸer liste ise (eski format), boÅŸ dict dÃ¶ndÃ¼r
        if isinstance(settings_data, list):
            settings = {}
        else:
            settings = settings_data
        
        # VarsayÄ±lan ayarlar
        default_settings = {
            "auto_mode": False,
            "min_score": 5,
            "check_interval_hours": 3,
            "max_articles_per_run": 10,
            "auto_post_enabled": False,
            "require_manual_approval": True,
            "working_hours_only": False,
            "working_hours_start": "09:00",
            "working_hours_end": "18:00",
            "weekend_enabled": True,
            "last_updated": datetime.now().isoformat()
        }
        
        # Eksik ayarlarÄ± varsayÄ±lanlarla doldur
        for key, value in default_settings.items():
            if key not in settings:
                settings[key] = value
        
        return settings
        
    except Exception as e:
        print(f"Ayarlar yÃ¼kleme hatasÄ±: {e}")
        # VarsayÄ±lan ayarlarÄ± dÃ¶ndÃ¼r
        return {
            "auto_mode": False,
            "min_score": 5,
            "check_interval_hours": 3,
            "max_articles_per_run": 10,
            "auto_post_enabled": False,
            "require_manual_approval": True,
            "working_hours_only": False,
            "working_hours_start": "09:00",
            "working_hours_end": "18:00",
            "weekend_enabled": True,
            "last_updated": datetime.now().isoformat()
        }

def save_automation_settings(settings):
    """OtomatikleÅŸtirme ayarlarÄ±nÄ± kaydet"""
    try:
        settings["last_updated"] = datetime.now().isoformat()
        save_json("automation_settings.json", settings)
        return {"success": True, "message": "âœ… Ayarlar baÅŸarÄ±yla kaydedildi"}
    except Exception as e:
        return {"success": False, "message": f"âŒ Ayarlar kaydedilemedi: {e}"}

def get_automation_status():
    """OtomatikleÅŸtirme durumunu kontrol et"""
    try:
        settings = load_automation_settings()
        
        # Ã‡alÄ±ÅŸma saatleri kontrolÃ¼
        if settings.get("working_hours_only", False):
            from datetime import datetime, time
            now = datetime.now()
            start_time = datetime.strptime(settings.get("working_hours_start", "09:00"), "%H:%M").time()
            end_time = datetime.strptime(settings.get("working_hours_end", "18:00"), "%H:%M").time()
            
            current_time = now.time()
            is_working_hours = start_time <= current_time <= end_time
            
            # Hafta sonu kontrolÃ¼
            is_weekend = now.weekday() >= 5  # 5=Cumartesi, 6=Pazar
            weekend_allowed = settings.get("weekend_enabled", True)
            
            if is_weekend and not weekend_allowed:
                return {
                    "active": False,
                    "auto_mode": False,
                    "check_interval_hours": settings.get("check_interval_hours", 2),
                    "min_score_threshold": settings.get("min_score_threshold", 5),
                    "reason": "Hafta sonu Ã§alÄ±ÅŸma devre dÄ±ÅŸÄ±",
                    "settings": settings
                }
            
            if not is_working_hours:
                return {
                    "active": False,
                    "auto_mode": False,
                    "check_interval_hours": settings.get("check_interval_hours", 2),
                    "min_score_threshold": settings.get("min_score_threshold", 5),
                    "reason": f"Ã‡alÄ±ÅŸma saatleri dÄ±ÅŸÄ±nda ({start_time}-{end_time})",
                    "settings": settings
                }
        
        return {
            "active": settings.get("auto_mode", False),
            "auto_mode": settings.get("auto_mode", False),  # Template uyumluluÄŸu iÃ§in
            "check_interval_hours": settings.get("check_interval_hours", 2),
            "min_score_threshold": settings.get("min_score_threshold", 5),
            "reason": "Aktif" if settings.get("auto_mode", False) else "Manuel mod",
            "settings": settings
        }
        
    except Exception as e:
        return {
            "active": False,
            "auto_mode": False,
            "check_interval_hours": 2,
            "min_score_threshold": 5,
            "reason": f"Hata: {e}",
            "settings": {}
        }

def update_scheduler_settings():
    """Scheduler ayarlarÄ±nÄ± gÃ¼ncelle (scheduler.py iÃ§in)"""
    try:
        settings = load_automation_settings()
        
        # Scheduler iÃ§in ayarlar dosyasÄ± oluÅŸtur
        scheduler_config = {
            "auto_mode": settings.get("auto_mode", False),
            "min_score": settings.get("min_score", 5),
            "check_interval_hours": settings.get("check_interval_hours", 3),
            "max_articles_per_run": settings.get("max_articles_per_run", 10),
            "auto_post_enabled": settings.get("auto_post_enabled", False),
            "last_updated": datetime.now().isoformat()
        }
        
        save_json("scheduler_config.json", scheduler_config)
        return {"success": True, "message": "Scheduler ayarlarÄ± gÃ¼ncellendi"}
        
    except Exception as e:
        return {"success": False, "message": f"Scheduler ayarlarÄ± gÃ¼ncellenemedi: {e}"}

def validate_automation_settings(settings):
    """OtomatikleÅŸtirme ayarlarÄ±nÄ± doÄŸrula"""
    errors = []
    
    # Minimum skor kontrolÃ¼
    min_score = settings.get("min_score", 5)
    if not isinstance(min_score, int) or min_score < 1 or min_score > 10:
        errors.append("Minimum skor 1-10 arasÄ±nda olmalÄ±")
    
    # Kontrol aralÄ±ÄŸÄ± kontrolÃ¼
    interval = settings.get("check_interval_hours", 3)
    if not isinstance(interval, (int, float)) or interval < 0.5 or interval > 24:
        errors.append("Kontrol aralÄ±ÄŸÄ± 0.5-24 saat arasÄ±nda olmalÄ±")
    
    # Maksimum makale sayÄ±sÄ± kontrolÃ¼
    max_articles = settings.get("max_articles_per_run", 10)
    if not isinstance(max_articles, int) or max_articles < 1 or max_articles > 50:
        errors.append("Maksimum makale sayÄ±sÄ± 1-50 arasÄ±nda olmalÄ±")
    
    # Ã‡alÄ±ÅŸma saatleri kontrolÃ¼
    try:
        start_time = settings.get("working_hours_start", "09:00")
        end_time = settings.get("working_hours_end", "18:00")
        datetime.strptime(start_time, "%H:%M")
        datetime.strptime(end_time, "%H:%M")
    except ValueError:
        errors.append("Ã‡alÄ±ÅŸma saatleri HH:MM formatÄ±nda olmalÄ±")
    

    
    return errors

def send_telegram_notification(message, tweet_url="", article_title=""):
    """Telegram bot'a bildirim gÃ¶nder - Bot token env'den, Chat ID settings'den"""
    try:
        # Bot token'Ä± environment variable'dan Ã§ek
        bot_token = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
        
        # Chat ID'yi settings'den Ã§ek
        settings = load_automation_settings()
        chat_id = settings.get("telegram_chat_id", "").strip()
        
        # EÄŸer bot token env'de yoksa settings'den dene (geriye dÃ¶nÃ¼k uyumluluk)
        if not bot_token:
            bot_token = settings.get("telegram_bot_token", "").strip()
        
        # Telegram bildirimleri kapalÄ± mÄ± kontrol et
        if not settings.get("telegram_notifications", True):  # VarsayÄ±lan True
            print("[DEBUG] Telegram bildirimleri kapalÄ±")
            return {"success": False, "reason": "disabled"}
        
        if not bot_token:
            safe_log("Telegram bot token eksik. .env dosyasÄ±nda TELEGRAM_BOT_TOKEN ayarlayÄ±n.", "WARNING")
            return {"success": False, "reason": "missing_bot_token"}
            
        if not chat_id:
            print("[INFO] Chat ID eksik, otomatik algÄ±lama deneniyor...")
            # Otomatik Chat ID algÄ±lamayÄ± dene
            auto_result = auto_detect_and_save_chat_id()
            
            if auto_result["success"]:
                chat_id = auto_result["chat_id"]
                print(f"[SUCCESS] Chat ID otomatik algÄ±landÄ±: {chat_id}")
            else:
                print(f"[WARNING] Chat ID otomatik algÄ±lanamadÄ±: {auto_result.get('error', 'Bilinmeyen hata')}")
                print("[INFO] Bot'a @tweet62_bot adresinden bir mesaj gÃ¶nderin ve tekrar deneyin.")
                return {"success": False, "reason": "missing_chat_id", "auto_detect_error": auto_result.get('error')}
        
        # Telegram mesajÄ±nÄ± hazÄ±rla
        telegram_message = f"ğŸ¤– **Yeni Tweet PaylaÅŸÄ±ldÄ±!**\n\n"
        
        if article_title:
            telegram_message += f"ğŸ“° **Makale:** {article_title}\n\n"
        
        telegram_message += f"ğŸ’¬ **Tweet:** {message}\n\n"
        
        if tweet_url:
            telegram_message += f"ğŸ”— **Link:** {tweet_url}\n\n"
        
        telegram_message += f"â° **Zaman:** {datetime.now().strftime('%d.%m.%Y %H:%M')}"
        
        # Telegram API'ye gÃ¶nder
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        
        payload = {
            "chat_id": str(chat_id),
            "text": telegram_message,
            "parse_mode": "Markdown",
            "disable_web_page_preview": False
        }
        
        response = requests.post(url, json=payload, timeout=10)
        
        if response.status_code == 200:
            print(f"[SUCCESS] Telegram bildirimi gÃ¶nderildi: {chat_id}")
            return {"success": True, "message_id": response.json().get("result", {}).get("message_id")}
        else:
            print(f"[ERROR] Telegram API hatasÄ±: {response.status_code} - {response.text}")
            return {"success": False, "error": f"API Error: {response.status_code}"}
            
    except Exception as e:
        print(f"[ERROR] Telegram bildirim hatasÄ±: {e}")
        return {"success": False, "error": str(e)}

def test_telegram_connection():
    """Telegram bot baÄŸlantÄ±sÄ±nÄ± test et - Bot token env'den, Chat ID settings'den"""
    try:
        # Bot token'Ä± environment variable'dan Ã§ek
        bot_token = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
        
        # Chat ID'yi settings'den Ã§ek
        settings = load_automation_settings()
        chat_id = settings.get("telegram_chat_id", "").strip()
        
        # EÄŸer bot token env'de yoksa settings'den dene (geriye dÃ¶nÃ¼k uyumluluk)
        if not bot_token:
            bot_token = settings.get("telegram_bot_token", "").strip()
        
        if not bot_token:
            return {
                "success": False, 
                "error": "Bot token eksik. .env dosyasÄ±nda TELEGRAM_BOT_TOKEN ayarlayÄ±n."
            }
            
        if not chat_id:
            print("[INFO] Chat ID eksik, otomatik algÄ±lama deneniyor...")
            # Otomatik Chat ID algÄ±lamayÄ± dene
            auto_result = auto_detect_and_save_chat_id()
            
            if auto_result["success"]:
                chat_id = auto_result["chat_id"]
                print(f"[SUCCESS] Chat ID otomatik algÄ±landÄ±: {chat_id}")
            else:
                return {
                    "success": False, 
                    "error": f"Chat ID eksik ve otomatik algÄ±lanamadÄ±: {auto_result.get('error', 'Bilinmeyen hata')}. Bot'a @tweet62_bot adresinden bir mesaj gÃ¶nderin."
                }
        
        # Bot bilgilerini al
        url = f"https://api.telegram.org/bot{bot_token}/getMe"
        response = requests.get(url, timeout=10)
        
        if response.status_code != 200:
            return {"success": False, "error": f"Bot token geÃ§ersiz: {response.status_code}"}
        
        bot_info = response.json().get("result", {})
        
        # Test mesajÄ± gÃ¶nder
        test_message = f"ğŸ§ª **Test MesajÄ±**\n\nBot baÅŸarÄ±yla baÄŸlandÄ±!\n\nâ° {datetime.now().strftime('%d.%m.%Y %H:%M')}"
        
        send_url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        payload = {
            "chat_id": str(chat_id),
            "text": test_message,
            "parse_mode": "Markdown"
        }
        
        send_response = requests.post(send_url, json=payload, timeout=10)
        
        if send_response.status_code == 200:
            return {
                "success": True, 
                "bot_name": bot_info.get("first_name", "Unknown"),
                "bot_username": bot_info.get("username", "Unknown")
            }
        else:
            error_detail = send_response.text
            return {"success": False, "error": f"Mesaj gÃ¶nderilemedi: {send_response.status_code} - {error_detail}"}
            
    except Exception as e:
        return {"success": False, "error": str(e)}

def check_telegram_configuration():
    """Telegram konfigÃ¼rasyonunu kontrol et - Bot token env'den, Chat ID settings'den"""
    try:
        # Bot token environment variable'dan
        bot_token = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
        
        # Chat ID settings'den
        settings = load_automation_settings()
        chat_id = settings.get("telegram_chat_id", "").strip()
        
        # Geriye dÃ¶nÃ¼k uyumluluk iÃ§in settings'den bot token kontrol et
        settings_bot_token = settings.get("telegram_bot_token", "").strip()
        
        status = {
            "bot_token_env": bool(bot_token),
            "bot_token_settings": bool(settings_bot_token),
            "chat_id_set": bool(chat_id),
            "ready": bool((bot_token or settings_bot_token) and chat_id)
        }
        
        if status["ready"]:
            if status["bot_token_env"]:
                status["message"] = "âœ… Telegram yapÄ±landÄ±rmasÄ± tamamlanmÄ±ÅŸ (Bot token: ENV, Chat ID: Ayarlar)"
            else:
                status["message"] = "âœ… Telegram yapÄ±landÄ±rmasÄ± tamamlanmÄ±ÅŸ (Bot token: Ayarlar, Chat ID: Ayarlar)"
            status["status"] = "ready"
        elif status["bot_token_env"] or status["bot_token_settings"]:
            if not status["chat_id_set"]:
                status["message"] = "âš ï¸ Bot token var, Chat ID eksik - 'Chat ID Bul' butonu ile ayarlayÄ±n"
                status["status"] = "partial"
            else:
                status["message"] = "âœ… Telegram yapÄ±landÄ±rmasÄ± tamamlanmÄ±ÅŸ"
                status["status"] = "ready"
        else:
            status["message"] = "âŒ Bot token eksik - .env dosyasÄ±nda TELEGRAM_BOT_TOKEN ayarlayÄ±n"
            status["status"] = "missing"
            
        return status
        
    except Exception as e:
        return {
            "bot_token_env": False,
            "bot_token_settings": False,
            "chat_id_set": False,
            "ready": False,
            "message": f"âŒ Kontrol hatasÄ±: {e}",
            "status": "error"
        }

def get_telegram_chat_id(bot_token=None):
    """Bot'a mesaj gÃ¶nderen kullanÄ±cÄ±larÄ±n chat ID'lerini al - Environment variable'lardan token Ã§eker"""
    try:
        # EÄŸer bot_token parametre olarak verilmemiÅŸse env'den Ã§ek
        if not bot_token:
            bot_token = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
            
            # EÄŸer env'de yoksa settings'den dene
            if not bot_token:
                settings = load_automation_settings()
                bot_token = settings.get("telegram_bot_token", "").strip()
        
        if not bot_token:
            return {
                "success": False, 
                "error": "Bot token eksik. .env dosyasÄ±nda TELEGRAM_BOT_TOKEN ayarlayÄ±n."
            }
        
        url = f"https://api.telegram.org/bot{bot_token}/getUpdates"
        response = requests.get(url, timeout=10)
        
        if response.status_code != 200:
            return {"success": False, "error": "Bot token geÃ§ersiz"}
        
        data = response.json()
        updates = data.get("result", [])
        
        chat_ids = []
        for update in updates[-10:]:  # Son 10 mesaj
            message = update.get("message", {})
            chat = message.get("chat", {})
            if chat.get("id"):
                chat_info = {
                    "chat_id": chat.get("id"),
                    "type": chat.get("type"),
                    "title": chat.get("title") or f"{chat.get('first_name', '')} {chat.get('last_name', '')}".strip()
                }
                if chat_info not in chat_ids:
                    chat_ids.append(chat_info)
        
        return {"success": True, "chat_ids": chat_ids}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def save_telegram_chat_id(chat_id):
    """Chat ID'yi otomatik olarak ayarlara kaydet"""
    try:
        settings = load_automation_settings()
        settings["telegram_chat_id"] = str(chat_id).strip()
        
        save_result = save_automation_settings(settings)
        
        if save_result["success"]:
            print(f"[SUCCESS] Chat ID otomatik kaydedildi: {chat_id}")
            return {"success": True, "message": f"âœ… Chat ID kaydedildi: {chat_id}"}
        else:
            print(f"[ERROR] Chat ID kaydetme hatasÄ±: {save_result['message']}")
            return {"success": False, "error": f"Kaydetme hatasÄ±: {save_result['message']}"}
            
    except Exception as e:
        print(f"[ERROR] Chat ID kaydetme hatasÄ±: {e}")
        return {"success": False, "error": str(e)}

def auto_detect_and_save_chat_id():
    """Otomatik chat ID tespit et ve kaydet"""
    try:
        # Mevcut chat ID'yi kontrol et
        settings = load_automation_settings()
        current_chat_id = settings.get("telegram_chat_id", "").strip()
        
        if current_chat_id:
            return {
                "success": True, 
                "message": f"Chat ID zaten ayarlanmÄ±ÅŸ: {current_chat_id}",
                "chat_id": current_chat_id,
                "auto_detected": False
            }
        
        # Chat ID'leri bul
        result = get_telegram_chat_id()
        
        if not result["success"]:
            return {
                "success": False,
                "error": result["error"],
                "auto_detected": False
            }
        
        chat_ids = result.get("chat_ids", [])
        
        if not chat_ids:
            return {
                "success": False,
                "error": "Chat ID bulunamadÄ±. Bot'a Ã¶nce bir mesaj gÃ¶nderin.",
                "auto_detected": False
            }
        
        # Ä°lk chat ID'yi otomatik seÃ§ (genellikle en son mesaj)
        selected_chat = chat_ids[0]
        chat_id = selected_chat["chat_id"]
        
        # Chat ID'yi kaydet
        save_result = save_telegram_chat_id(chat_id)
        
        if save_result["success"]:
            return {
                "success": True,
                "message": f"âœ… Chat ID otomatik tespit edildi ve kaydedildi: {chat_id}",
                "chat_id": chat_id,
                "chat_info": selected_chat,
                "auto_detected": True,
                "all_chats": chat_ids
            }
        else:
            return {
                "success": False,
                "error": save_result["error"],
                "auto_detected": False
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "auto_detected": False
        }

def load_mcp_config():
    """MCP konfigÃ¼rasyonunu yÃ¼kle"""
    try:
        if os.path.exists(MCP_CONFIG_FILE):
            config = load_json(MCP_CONFIG_FILE)
        else:
            # VarsayÄ±lan konfigÃ¼rasyon
            config = {
                "mcp_enabled": False,
                "firecrawl_mcp": {
                    "enabled": False,
                    "server_url": "http://localhost:3000",
                    "api_key": "",
                    "timeout": 30,
                    "retry_count": 3,
                    "fallback_enabled": True
                },
                "content_extraction": {
                    "max_content_length": 2500,
                    "min_content_length": 100,
                    "wait_time": 3000,
                    "remove_base64_images": True,
                    "only_main_content": True
                },
                "ai_analysis": {
                    "enabled": True,
                    "max_tokens": 300,
                    "temperature": 0.7,
                    "model": "deepseek/deepseek-chat-v3-0324:free",
                    "fallback_enabled": True
                },
                "last_updated": datetime.now().isoformat()
            }
            save_json(MCP_CONFIG_FILE, config)
        
        return config
        
    except Exception as e:
        print(f"MCP konfigÃ¼rasyon yÃ¼kleme hatasÄ±: {e}")
        return {
            "mcp_enabled": False,
            "firecrawl_mcp": {"enabled": False, "fallback_enabled": True},
            "ai_analysis": {"enabled": True, "fallback_enabled": True}
        }

def save_mcp_config(config):
    """MCP konfigÃ¼rasyonunu kaydet"""
    try:
        config["last_updated"] = datetime.now().isoformat()
        save_json(MCP_CONFIG_FILE, config)
        return {"success": True, "message": "âœ… MCP konfigÃ¼rasyonu kaydedildi"}
    except Exception as e:
        return {"success": False, "message": f"âŒ MCP konfigÃ¼rasyonu kaydedilemedi: {e}"}

def get_mcp_status():
    """MCP durumunu kontrol et"""
    try:
        config = load_mcp_config()
        
        status = {
            "mcp_enabled": config.get("mcp_enabled", False),
            "firecrawl_enabled": config.get("firecrawl_mcp", {}).get("enabled", False),
            "ai_analysis_enabled": config.get("ai_analysis", {}).get("enabled", True),
            "fallback_available": True,
            "ready": False
        }
        
        # MCP hazÄ±r mÄ± kontrol et
        if status["mcp_enabled"] and status["firecrawl_enabled"]:
            # Firecrawl MCP server baÄŸlantÄ±sÄ±nÄ± test et
            try:
                server_url = config.get("firecrawl_mcp", {}).get("server_url", "")
                if server_url:
                    # Basit ping testi (gerÃ§ek implementasyonda MCP server'a ping atÄ±lacak)
                    status["ready"] = True
                    status["message"] = "âœ… MCP Firecrawl aktif ve hazÄ±r"
                else:
                    status["message"] = "âš ï¸ MCP server URL'si eksik"
            except:
                status["message"] = "âŒ MCP server baÄŸlantÄ±sÄ± baÅŸarÄ±sÄ±z"
        elif status["ai_analysis_enabled"]:
            status["message"] = "âœ… AI analizi aktif (MCP olmadan)"
        else:
            status["message"] = "âš ï¸ MCP ve AI analizi devre dÄ±ÅŸÄ±"
        
        return status
        
    except Exception as e:
        return {
            "mcp_enabled": False,
            "firecrawl_enabled": False,
            "ai_analysis_enabled": True,
            "fallback_available": True,
            "ready": False,
            "message": f"âŒ MCP durum kontrolÃ¼ hatasÄ±: {e}"
        }

def test_mcp_connection():
    """MCP baÄŸlantÄ±sÄ±nÄ± test et"""
    try:
        config = load_mcp_config()
        
        if not config.get("mcp_enabled", False):
            return {
                "success": False,
                "message": "MCP devre dÄ±ÅŸÄ±",
                "details": "MCP konfigÃ¼rasyondan etkinleÅŸtirilmeli"
            }
        
        firecrawl_config = config.get("firecrawl_mcp", {})
        
        if not firecrawl_config.get("enabled", False):
            return {
                "success": False,
                "message": "Firecrawl MCP devre dÄ±ÅŸÄ±",
                "details": "Firecrawl MCP konfigÃ¼rasyondan etkinleÅŸtirilmeli"
            }
        
        server_url = firecrawl_config.get("server_url", "")
        
        if not server_url:
            return {
                "success": False,
                "message": "MCP server URL'si eksik",
                "details": "KonfigÃ¼rasyonda server_url ayarlanmalÄ±"
            }
        
        # GerÃ§ek MCP implementasyonunda burada MCP server'a test Ã§aÄŸrÄ±sÄ± yapÄ±lacak
        # Åimdilik simÃ¼le ediyoruz
        print(f"[TEST] MCP server test ediliyor: {server_url}")
        
        # Test URL'si ile basit scrape denemesi
        test_result = mcp_firecrawl_scrape({
            "url": "https://example.com",
            "formats": ["markdown"],
            "onlyMainContent": True
        })
        
        if test_result.get("success", False):
            return {
                "success": True,
                "message": "âœ… MCP Firecrawl baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±",
                "details": f"Server: {server_url}"
            }
        else:
            return {
                "success": False,
                "message": "âŒ MCP Firecrawl test baÅŸarÄ±sÄ±z",
                "details": test_result.get("reason", "Bilinmeyen hata")
            }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ MCP test hatasÄ±: {e}",
            "details": "BaÄŸlantÄ± testi sÄ±rasÄ±nda hata oluÅŸtu"
        }

def gemini_ocr_image(image_path):
    import google.generativeai as genai
    import os
    from PIL import Image

    api_key = os.environ.get('GOOGLE_API_KEY')
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.0-flash')

    # Resmi PIL ile aÃ§
    image = Image.open(image_path)
    prompt = "Bu gÃ¶rseldeki tÃ¼m metni OCR ile Ã§Ä±kar ve sadece metni dÃ¶ndÃ¼r."
    response = model.generate_content([prompt, image])
    return response.text.strip()

def setup_twitter_v2_client():
    """Tweepy v2 API Client ile kimlik doÄŸrulama (sadece metinli tweet iÃ§in)"""
    import tweepy
    import os
    # v2 API Client
    client = tweepy.Client(
        bearer_token=os.environ.get('TWITTER_BEARER_TOKEN'),
        consumer_key=os.environ.get('TWITTER_API_KEY'),
        consumer_secret=os.environ.get('TWITTER_API_SECRET'),
        access_token=os.environ.get('TWITTER_ACCESS_TOKEN'),
        access_token_secret=os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')
    )
    return client



def post_text_tweet_v2(tweet_text):
    """Sadece metinli tweet atmak iÃ§in Tweepy v2 API kullanÄ±mÄ± - Rate limit kontrolÃ¼ ile"""
    try:
        import tweepy
        
        # Rate limit kontrolÃ¼ yap
        rate_check = check_rate_limit("tweets")
        if not rate_check.get("allowed", True):
            wait_minutes = int(rate_check.get("wait_time", 0) / 60) + 1
            error_msg = f"Twitter API rate limit aÅŸÄ±ldÄ±. {wait_minutes} dakika sonra tekrar deneyin. ({rate_check.get('requests_made', 0)}/{rate_check.get('limit', 300)} istek kullanÄ±ldÄ±)"
            safe_log(error_msg, "WARNING")
            return {"success": False, "error": error_msg, "rate_limited": True, "wait_minutes": wait_minutes}
        
        client = setup_twitter_v2_client()
        TWITTER_LIMIT = 280
        if len(tweet_text) > TWITTER_LIMIT:
            tweet_text = tweet_text[:TWITTER_LIMIT-3] + "..."
        safe_log(f"Tweet uzunluÄŸu: {len(tweet_text)}", "DEBUG")
        
        response = client.create_tweet(text=tweet_text)
        
        # Rate limit kullanÄ±mÄ±nÄ± gÃ¼ncelle
        update_rate_limit_usage("tweets")
        
        if hasattr(response, 'data') and response.data and 'id' in response.data:
            tweet_id = response.data['id']
            tweet_url = f"https://twitter.com/user/status/{tweet_id}"
            safe_log(f"Tweet baÅŸarÄ±yla gÃ¶nderildi: {tweet_url}", "INFO")
            return {"success": True, "tweet_id": tweet_id, "url": tweet_url}
        else:
            safe_log(f"Tweet gÃ¶nderilemedi: {response}", "ERROR")
            return {"success": False, "error": "Tweet gÃ¶nderilemedi"}
            
    except tweepy.TooManyRequests as rate_limit_error:
        # API'den gelen rate limit bilgilerini gÃ¼ncelle
        try:
            # Rate limit durumunu gÃ¼ncelle
            status = load_rate_limit_status()
            current_time = time.time()
            if "tweets" not in status:
                status["tweets"] = {}
            status["tweets"]["requests"] = TWITTER_RATE_LIMITS["tweets"]["limit"]  # Limit dolu
            status["tweets"]["reset_time"] = current_time + 3600  # 1 saat sonra reset (Free plan iÃ§in gÃ¼venli)
            save_rate_limit_status(status)
        except:
            pass
        
        wait_minutes = 15  # Twitter API rate limit genelde 15 dakika
        error_msg = f"Twitter API rate limit aÅŸÄ±ldÄ±: {rate_limit_error}\n{wait_minutes} dakika sonra tekrar deneyin."
        safe_log(error_msg, "WARNING")
        return {"success": False, "error": error_msg, "rate_limited": True, "wait_minutes": wait_minutes}
        
    except tweepy.Unauthorized as auth_error:
        safe_log(f"Twitter API yetkilendirme hatasÄ±: {auth_error}", "ERROR")
        return {"success": False, "error": f"Twitter API yetkilendirme hatasÄ±: {auth_error}"}
        
    except tweepy.Forbidden as forbidden_error:
        safe_log(f"Twitter API yasak iÅŸlem: {forbidden_error}", "ERROR")
        return {"success": False, "error": f"Twitter API yasak iÅŸlem: {forbidden_error}"}
        
    except Exception as e:
        safe_log(f"Tweet paylaÅŸÄ±m genel hatasÄ±: {e}", "ERROR")
        return {"success": False, "error": str(e)}

def fetch_url_content_with_mcp(url):
    """MCP ile URL iÃ§eriÄŸi Ã§ekme - Tweet oluÅŸturma iÃ§in"""
    try:
        print(f"ğŸ” MCP ile URL iÃ§eriÄŸi Ã§ekiliyor: {url}")
        
        # Firecrawl MCP scrape fonksiyonunu kullan
        scrape_result = mcp_firecrawl_scrape({
            "url": url,
            "formats": ["markdown"],
            "onlyMainContent": True,
            "waitFor": 3000,
            "removeBase64Images": True
        })
        
        if not scrape_result.get("success", False):
            print(f"âš ï¸ MCP baÅŸarÄ±sÄ±z, fallback deneniyor...")
            return fetch_url_content_fallback(url)
        
        # Markdown iÃ§eriÄŸini al
        markdown_content = scrape_result.get("markdown", "")
        
        if not markdown_content or len(markdown_content) < 100:
            print(f"âš ï¸ MCP'den yetersiz iÃ§erik, fallback deneniyor...")
            return fetch_url_content_fallback(url)
        
        # BaÅŸlÄ±ÄŸÄ± Ã§Ä±kar (genellikle ilk # ile baÅŸlar)
        lines = markdown_content.split('\n')
        title = ""
        content_lines = []
        
        for line in lines:
            line = line.strip()
            if line.startswith('# ') and not title:
                title = line[2:].strip()
            elif line and not line.startswith('#') and len(line) > 20:
                content_lines.append(line)
        
        # Ä°Ã§eriÄŸi birleÅŸtir ve temizle
        content = '\n'.join(content_lines)
        
        # Gereksiz karakterleri temizle
        content = content.replace('*', '').replace('**', '').replace('_', '')
        content = ' '.join(content.split())  # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
        
        # Ä°Ã§eriÄŸi sÄ±nÄ±rla
        content = content[:2000]
        
        print(f"âœ… MCP ile URL iÃ§eriÄŸi Ã§ekildi: {len(content)} karakter")
        
        return {
            "title": title or "BaÅŸlÄ±k bulunamadÄ±",
            "content": content,
            "url": url,
            "source": "mcp"
        }
        
    except Exception as e:
        print(f"âŒ MCP URL Ã§ekme hatasÄ± ({url}): {e}")
        print("ğŸ”„ Fallback yÃ¶nteme geÃ§iliyor...")
        return fetch_url_content_fallback(url)

def fetch_url_content_fallback(url):
    """Fallback URL iÃ§eriÄŸi Ã§ekme - BeautifulSoup ile"""
    try:
        print(f"ğŸ”„ Fallback ile URL iÃ§eriÄŸi Ã§ekiliyor: {url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # BaÅŸlÄ±ÄŸÄ± bul
        title = ""
        title_selectors = ["h1", "h1.entry-title", "h1.post-title", ".article-title h1", "title"]
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.text.strip()
                break
        
        # Ä°Ã§eriÄŸi bul - Ã§oklu selector deneme
        content_selectors = [
            "article p",
            "div.article-content p",
            "div.entry-content p", 
            "div.post-content p",
            "div.content p",
            ".article-body p",
            "main p",
            ".post p"
        ]
        
        content = ""
        for selector in content_selectors:
            paragraphs = soup.select(selector)
            if paragraphs:
                content = "\n".join([p.text.strip() for p in paragraphs if p.text.strip() and len(p.text.strip()) > 20])
                if len(content) > 200:  # Yeterli iÃ§erik bulundu
                    break
        
        # EÄŸer hala iÃ§erik bulunamadÄ±ysa, tÃ¼m p etiketlerini dene
        if not content:
            all_paragraphs = soup.find_all('p')
            content = "\n".join([p.text.strip() for p in all_paragraphs if len(p.text.strip()) > 30])
        
        # Ä°Ã§eriÄŸi temizle ve sÄ±nÄ±rla
        content = ' '.join(content.split())  # Ã‡oklu boÅŸluklarÄ± temizle
        content = content[:2000]  # Ä°Ã§eriÄŸi sÄ±nÄ±rla
        
        print(f"âœ… Fallback ile URL iÃ§eriÄŸi Ã§ekildi: {len(content)} karakter")
        
        return {
            "title": title or "BaÅŸlÄ±k bulunamadÄ±",
            "content": content,
            "url": url,
            "source": "fallback"
        }
        
    except Exception as e:
        print(f"âŒ Fallback URL Ã§ekme hatasÄ± ({url}): {e}")
        return {
            "title": "Ä°Ã§erik Ã§ekilemedi",
            "content": f"URL: {url} - Ä°Ã§erik Ã§ekilemedi: {str(e)}",
            "url": url,
            "source": "error"
        }

# =============================================================================
# GMAIL E-POSTA BÄ°LDÄ°RÄ°M SÄ°STEMÄ°
# =============================================================================

def send_gmail_notification(message, tweet_url="", article_title=""):
    """Gmail SMTP ile e-posta bildirimi gÃ¶nder"""
    try:
        import smtplib
        from email.mime.text import MIMEText
        from email.mime.multipart import MIMEMultipart
        from datetime import datetime
        import os
        
        # Gmail SMTP ayarlarÄ±
        gmail_email = os.getenv("GMAIL_EMAIL", "").strip()
        gmail_password = os.getenv("GMAIL_APP_PASSWORD", "").strip()
        
        # AyarlarÄ± kontrol et
        settings = load_automation_settings()
        email_notifications = settings.get("email_notifications", True)
        
        if not email_notifications:
            print("[DEBUG] E-posta bildirimleri kapalÄ±")
            return {"success": False, "reason": "disabled"}
        
        if not gmail_email:
            print("[WARNING] Gmail e-posta adresi eksik. .env dosyasÄ±nda GMAIL_EMAIL ayarlayÄ±n.")
            return {"success": False, "reason": "missing_email"}
            
        if not gmail_password:
            safe_log("Gmail uygulama ÅŸifresi eksik. .env dosyasÄ±nda GMAIL_APP_PASSWORD ayarlayÄ±n.", "WARNING")
            return {"success": False, "reason": "missing_password"}
        
        # E-posta iÃ§eriÄŸini hazÄ±rla
        subject = "ğŸ¤– AI Tweet Bot - Yeni Tweet PaylaÅŸÄ±ldÄ±!"
        
        # HTML e-posta iÃ§eriÄŸi
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }}
                .container {{ max-width: 600px; margin: 0 auto; padding: 20px; }}
                .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px 10px 0 0; text-align: center; }}
                .content {{ background: #f9f9f9; padding: 20px; border-radius: 0 0 10px 10px; }}
                .tweet-box {{ background: white; border-left: 4px solid #1da1f2; padding: 15px; margin: 15px 0; border-radius: 5px; }}
                .article-box {{ background: white; border-left: 4px solid #28a745; padding: 15px; margin: 15px 0; border-radius: 5px; }}
                .footer {{ text-align: center; margin-top: 20px; color: #666; font-size: 12px; }}
                .btn {{ display: inline-block; background: #1da1f2; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; margin: 10px 5px; }}
                .stats {{ background: #e3f2fd; padding: 10px; border-radius: 5px; margin: 10px 0; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ¤– AI Tweet Bot</h1>
                    <p>Yeni Tweet BaÅŸarÄ±yla PaylaÅŸÄ±ldÄ±!</p>
                </div>
                
                <div class="content">
                    <div class="tweet-box">
                        <h3>ğŸ’¬ PaylaÅŸÄ±lan Tweet:</h3>
                        <p><strong>{message}</strong></p>
                        {f'<a href="{tweet_url}" class="btn">ğŸ”— Tweet&apos;i GÃ¶rÃ¼ntÃ¼le</a>' if tweet_url else ''}
                    </div>
                    
                    {f'''
                    <div class="article-box">
                        <h3>ğŸ“° Kaynak Makale:</h3>
                        <p><strong>{article_title}</strong></p>
                    </div>
                    ''' if article_title else ''}
                    
                    <div class="stats">
                        <h3>ğŸ“Š Sistem Bilgileri:</h3>
                        <p><strong>â° Zaman:</strong> {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}</p>
                        <p><strong>ğŸ¤– Bot:</strong> AI Tweet Bot v2.0</p>
                        <p><strong>ğŸ”„ Durum:</strong> Otomatik paylaÅŸÄ±m aktif</p>
                    </div>
                </div>
                
                <div class="footer">
                    <p>Bu e-posta AI Tweet Bot tarafÄ±ndan otomatik olarak gÃ¶nderilmiÅŸtir.</p>
                    <p>Bildirimleri kapatmak iÃ§in uygulama ayarlarÄ±ndan e-posta bildirimlerini devre dÄ±ÅŸÄ± bÄ±rakabilirsiniz.</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # Metin versiyonu (fallback)
        text_content = f"""
ğŸ¤– AI Tweet Bot - Yeni Tweet PaylaÅŸÄ±ldÄ±!

ğŸ’¬ Tweet: {message}

{f'ğŸ“° Makale: {article_title}' if article_title else ''}

{f'ğŸ”— Tweet Linki: {tweet_url}' if tweet_url else ''}

â° Zaman: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}

Bu e-posta AI Tweet Bot tarafÄ±ndan otomatik olarak gÃ¶nderilmiÅŸtir.
        """
        
        # E-posta mesajÄ±nÄ± oluÅŸtur
        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = gmail_email
        msg['To'] = gmail_email  # Kendine gÃ¶nder
        
        # Metin ve HTML parÃ§alarÄ±nÄ± ekle
        text_part = MIMEText(text_content, 'plain', 'utf-8')
        html_part = MIMEText(html_content, 'html', 'utf-8')
        
        msg.attach(text_part)
        msg.attach(html_part)
        
        # Gmail SMTP ile gÃ¶nder
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(gmail_email, gmail_password)
            server.send_message(msg)
        
        print(f"[SUCCESS] Gmail bildirimi gÃ¶nderildi: {gmail_email}")
        return {"success": True, "email": gmail_email}
        
    except Exception as e:
        print(f"[ERROR] Gmail bildirim hatasÄ±: {e}")
        return {"success": False, "error": str(e)}

def test_gmail_connection():
    """Gmail SMTP baÄŸlantÄ±sÄ±nÄ± test et"""
    try:
        import smtplib
        from email.mime.text import MIMEText
        from datetime import datetime
        import os
        
        gmail_email = os.getenv("GMAIL_EMAIL", "").strip()
        gmail_password = os.getenv("GMAIL_APP_PASSWORD", "").strip()
        
        if not gmail_email:
            return {
                "success": False, 
                "error": "Gmail e-posta adresi eksik. .env dosyasÄ±nda GMAIL_EMAIL ayarlayÄ±n."
            }
            
        if not gmail_password:
            return {
                "success": False, 
                "error": "Gmail uygulama ÅŸifresi eksik. .env dosyasÄ±nda GMAIL_APP_PASSWORD ayarlayÄ±n."
            }
        
        # Test e-postasÄ± gÃ¶nder
        subject = "ğŸ§ª AI Tweet Bot - Test E-postasÄ±"
        body = f"""
ğŸ§ª Test E-postasÄ±

Gmail SMTP baÄŸlantÄ±sÄ± baÅŸarÄ±yla test edildi!

â° Test ZamanÄ±: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}
ğŸ“§ E-posta: {gmail_email}
ğŸ¤– AI Tweet Bot v2.0

Bu bir test e-postasÄ±dÄ±r.
        """
        
        msg = MIMEText(body, 'plain', 'utf-8')
        msg['Subject'] = subject
        msg['From'] = gmail_email
        msg['To'] = gmail_email
        
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login(gmail_email, gmail_password)
            server.send_message(msg)
        
        return {
            "success": True, 
            "message": f"âœ… Test e-postasÄ± baÅŸarÄ±yla gÃ¶nderildi: {gmail_email}"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def check_gmail_configuration():
    """Gmail konfigÃ¼rasyonunu kontrol et"""
    try:
        import os
        
        gmail_email = os.getenv("GMAIL_EMAIL", "").strip()
        gmail_password = os.getenv("GMAIL_APP_PASSWORD", "").strip()
        
        # AyarlarÄ± kontrol et
        settings = load_automation_settings()
        email_notifications = settings.get("email_notifications", True)
        
        status = {
            "email_set": bool(gmail_email and "@" in gmail_email),
            "password_set": bool(gmail_password),
            "notifications_enabled": email_notifications,
            "ready": False
        }
        
        if status["email_set"] and status["password_set"] and status["notifications_enabled"]:
            status["ready"] = True
            status["message"] = "âœ… Gmail yapÄ±landÄ±rmasÄ± tamamlanmÄ±ÅŸ ve aktif"
            status["status"] = "ready"
        elif status["email_set"] and status["password_set"]:
            status["message"] = "âš ï¸ Gmail yapÄ±landÄ±rÄ±lmÄ±ÅŸ ama bildirimler kapalÄ±"
            status["status"] = "disabled"
        elif status["email_set"]:
            status["message"] = "âš ï¸ E-posta var, uygulama ÅŸifresi eksik"
            status["status"] = "partial"
        else:
            status["message"] = "âŒ Gmail yapÄ±landÄ±rmasÄ± eksik"
            status["status"] = "missing"
            
        return status
        
    except Exception as e:
        return {
            "email_set": False,
            "password_set": False,
            "notifications_enabled": False,
            "ready": False,
            "message": f"âŒ Kontrol hatasÄ±: {e}",
            "status": "error"
        }

# ==========================================
# Ã–ZEL HABER KAYNAKLARI YÃ–NETÄ°MÄ°
# ==========================================

NEWS_SOURCES_FILE = "news_sources.json"

def load_news_sources():
    """Haber kaynaklarÄ±nÄ± yÃ¼kle"""
    try:
        if os.path.exists(NEWS_SOURCES_FILE):
            return load_json(NEWS_SOURCES_FILE)
        else:
            # VarsayÄ±lan konfigÃ¼rasyon
            default_config = {
                "sources": [
                    {
                        "id": "techcrunch_ai",
                        "name": "TechCrunch AI",
                        "url": "https://techcrunch.com/category/artificial-intelligence/",
                        "description": "TechCrunch Yapay Zeka haberleri",
                        "enabled": True,
                        "selector_type": "rss_like",
                        "article_selectors": {
                            "container": "article.post-block",
                            "title": "h2.post-block__title a",
                            "link": "h2.post-block__title a",
                            "date": "time.river-byline__time",
                            "excerpt": ".post-block__content"
                        },
                        "added_date": datetime.now().isoformat(),
                        "last_checked": None,
                        "article_count": 0,
                        "success_rate": 100
                    }
                ],
                "settings": {
                    "max_sources": 10,
                    "check_all_sources": True,
                    "source_timeout": 30,
                    "articles_per_source": 5,
                    "last_updated": datetime.now().isoformat()
                }
            }
            save_json(NEWS_SOURCES_FILE, default_config)
            return default_config
    except Exception as e:
        print(f"Haber kaynaklarÄ± yÃ¼kleme hatasÄ±: {e}")
        return {"sources": [], "settings": {}}

def save_news_sources(config):
    """Haber kaynaklarÄ±nÄ± kaydet"""
    try:
        config["settings"]["last_updated"] = datetime.now().isoformat()
        save_json(NEWS_SOURCES_FILE, config)
        return {"success": True, "message": "âœ… Haber kaynaklarÄ± kaydedildi"}
    except Exception as e:
        return {"success": False, "message": f"âŒ Kaydetme hatasÄ±: {e}"}

def test_selectors_for_url(url):
    """URL iÃ§in selector'larÄ± test et ve Ã¶nerilerde bulun"""
    try:
        import requests
        from bs4 import BeautifulSoup
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Otomatik selector tespiti
        auto_selectors, container_count = auto_detect_selectors(soup, url)
        
        # Selector'larÄ± doÄŸrula
        is_valid, validation_msg = validate_selectors(soup, auto_selectors)
        
        if is_valid:
            # Ã–rnek makaleler Ã§ek
            sample_articles = []
            containers = soup.select(auto_selectors["container"])
            
            for container in containers[:3]:  # Ä°lk 3 makale
                try:
                    title_elem = container.select_one(auto_selectors["title"])
                    if title_elem:
                        title = title_elem.get_text(strip=True)
                        link_elem = title_elem if title_elem.name == 'a' else title_elem.find('a')
                        link = link_elem.get('href', '') if link_elem else ''
                        
                        if link.startswith('/'):
                            from urllib.parse import urljoin
                            link = urljoin(url, link)
                        
                        sample_articles.append({
                            'title': title[:100] + '...' if len(title) > 100 else title,
                            'link': link
                        })
                except:
                    continue
            
            return {
                'success': True,
                'message': validation_msg,
                'selectors': auto_selectors,
                'container_count': container_count,
                'sample_articles': sample_articles
            }
        else:
            return {
                'success': False,
                'message': validation_msg,
                'selectors': auto_selectors,
                'container_count': container_count
            }
            
    except Exception as e:
        return {
            'success': False,
            'message': f'Test hatasÄ±: {str(e)}'
        }

def add_news_source_with_validation(name, url, description="", auto_detect=True):
    """DoÄŸrulama ile yeni haber kaynaÄŸÄ± ekle"""
    try:
        config = load_news_sources()
        
        # URL'yi temizle ve doÄŸrula
        url = url.strip()
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        # AynÄ± URL var mÄ± kontrol et
        for source in config["sources"]:
            if source["url"] == url:
                return {
                    "success": False,
                    "message": f"âŒ Bu URL zaten mevcut: {source['name']}"
                }
        
        # Maksimum kaynak sayÄ±sÄ±nÄ± kontrol et
        max_sources = config["settings"].get("max_sources", 10)
        if len(config["sources"]) >= max_sources:
            return {"success": False, "message": f"âŒ Maksimum {max_sources} kaynak eklenebilir"}
        
        # URL'yi test et
        if auto_detect:
            print(f"ğŸ” {name} kaynaÄŸÄ± test ediliyor...")
            test_result = test_selectors_for_url(url)
            
            if not test_result['success']:
                return {
                    "success": False,
                    "message": f"âŒ URL test baÅŸarÄ±sÄ±z: {test_result['message']}",
                    "test_details": test_result
                }
            
            selectors = test_result['selectors']
            selector_type = "auto_detected"
            print(f"âœ… {name}: {test_result['container_count']} konteyner bulundu")
            
        else:
            # Manuel selector'lar
            selectors = {
                "container": "article, .article, .post, .news-item",
                "title": "h1, h2, h3, .title, .headline",
                "link": "a",
                "date": "time, .date, .published",
                "excerpt": ".excerpt, .summary, p"
            }
            selector_type = "manual"
        
        # Benzersiz ID oluÅŸtur
        import random
        source_id = f"custom_{len(config['sources']) + 1}_{random.randint(1000000000, 9999999999)}"
        
        # Yeni kaynak oluÅŸtur
        new_source = {
            "id": source_id,
            "name": name.strip(),
            "url": url,
            "description": description.strip(),
            "enabled": True,
            "selector_type": selector_type,
            "article_selectors": selectors,
            "added_date": datetime.now().isoformat(),
            "last_checked": datetime.now().isoformat(),
            "article_count": 0,
            "success_rate": 0
        }
        
        # KaynaÄŸÄ± ekle
        config["sources"].append(new_source)
        config["settings"]["last_updated"] = datetime.now().isoformat()
        
        # Kaydet
        result = save_news_sources(config)
        
        if result["success"]:
            response = {
                "success": True,
                "message": f"âœ… '{name}' kaynaÄŸÄ± baÅŸarÄ±yla eklendi",
                "source": new_source
            }
            
            # Test sonuÃ§larÄ±nÄ± da ekle
            if auto_detect and 'test_result' in locals():
                response['test_details'] = test_result
            
            return response
        else:
            return result
        
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ Kaynak ekleme hatasÄ±: {str(e)}"
        }

def add_news_source(name, url, description=""):
    """Yeni haber kaynaÄŸÄ± ekle (otomatik doÄŸrulama ile)"""
    return add_news_source_with_validation(name, url, description, auto_detect=True)

def remove_news_source(source_id):
    """Haber kaynaÄŸÄ±nÄ± kaldÄ±r"""
    try:
        config = load_news_sources()
        
        # KaynaÄŸÄ± bul ve kaldÄ±r
        original_count = len(config["sources"])
        config["sources"] = [s for s in config["sources"] if s["id"] != source_id]
        
        if len(config["sources"]) == original_count:
            return {"success": False, "message": "âŒ Kaynak bulunamadÄ±"}
        
        result = save_news_sources(config)
        if result["success"]:
            return {"success": True, "message": "âœ… Kaynak baÅŸarÄ±yla kaldÄ±rÄ±ldÄ±"}
        else:
            return result
            
    except Exception as e:
        return {"success": False, "message": f"âŒ Kaynak kaldÄ±rma hatasÄ±: {e}"}

def toggle_news_source(source_id, enabled=None):
    """Haber kaynaÄŸÄ±nÄ± aktif/pasif yap"""
    try:
        config = load_news_sources()
        
        for source in config["sources"]:
            if source["id"] == source_id:
                if enabled is None:
                    source["enabled"] = not source["enabled"]
                else:
                    source["enabled"] = bool(enabled)
                
                result = save_news_sources(config)
                if result["success"]:
                    status = "aktif" if source["enabled"] else "pasif"
                    return {"success": True, "message": f"âœ… '{source['name']}' kaynaÄŸÄ± {status} yapÄ±ldÄ±"}
                else:
                    return result
        
        return {"success": False, "message": "âŒ Kaynak bulunamadÄ±"}
        
    except Exception as e:
        return {"success": False, "message": f"âŒ Durum deÄŸiÅŸtirme hatasÄ±: {e}"}

def fetch_articles_from_custom_sources():
    """Ã–zel haber kaynaklarÄ±ndan makale Ã§ek"""
    try:
        config = load_news_sources()
        all_articles = []
        
        enabled_sources = [s for s in config["sources"] if s.get("enabled", True)]
        
        if not enabled_sources:
            print("âš ï¸ Aktif haber kaynaÄŸÄ± bulunamadÄ±")
            return []
        
        # Terminal log iÃ§in import
        try:
            from app import terminal_log
        except ImportError:
            # EÄŸer app.py'den import edilemezse normal print kullan
            def terminal_log(msg, level='info'):
                print(f"[{level.upper()}] {msg}")
        
        terminal_log(f"ğŸ” {len(enabled_sources)} haber kaynaÄŸÄ±ndan makale Ã§ekiliyor...", "info")
        
        for source in enabled_sources:
            try:
                terminal_log(f"ğŸ“° {source['name']} kaynaÄŸÄ± kontrol ediliyor...", "info")
                
                # Kaynak URL'sini Ã§ek
                articles = fetch_articles_from_single_source(source)
                
                if articles:
                    all_articles.extend(articles)
                    source["article_count"] = len(articles)
                    source["success_rate"] = min(100, source.get("success_rate", 0) + 10)
                    terminal_log(f"âœ… {source['name']}: {len(articles)} makale bulundu", "success")
                else:
                    source["success_rate"] = max(0, source.get("success_rate", 100) - 20)
                    terminal_log(f"âš ï¸ {source['name']}: Makale bulunamadÄ±", "warning")
                
                source["last_checked"] = datetime.now().isoformat()
                
            except Exception as e:
                terminal_log(f"âŒ {source['name']} hatasÄ±: {e}", "error")
                source["success_rate"] = max(0, source.get("success_rate", 100) - 30)
                source["last_checked"] = datetime.now().isoformat()
        
        # GÃ¼ncellenmiÅŸ istatistikleri kaydet
        save_news_sources(config)
        
        terminal_log(f"ğŸ“Š Toplam {len(all_articles)} makale Ã§ekildi", "info")
        
        # Duplikat filtreleme uygula
        if all_articles:
            filtered_articles = filter_duplicate_articles(all_articles)
            terminal_log(f"âœ… Duplikat filtreleme sonrasÄ± {len(filtered_articles)} benzersiz makale", "success")
            return filtered_articles
        
        return all_articles
        
    except Exception as e:
        print(f"âŒ Ã–zel kaynaklardan makale Ã§ekme hatasÄ±: {e}")
        return []

def auto_detect_selectors(soup, url):
    """Sayfadan otomatik olarak en iyi selector'larÄ± tespit et"""
    
    # YaygÄ±n makale konteyner pattern'leri (Ã¶ncelik sÄ±rasÄ±na gÃ¶re)
    container_patterns = [
        # Modern WordPress (TechCrunch tarzÄ±)
        "li.wp-block-post",
        "article.wp-block-post", 
        ".loop-card",
        
        # Modern haber siteleri
        "article[data-testid*='story']",
        "article[data-testid*='card']",
        ".story-card",
        ".news-item",
        
        # Genel WordPress
        "article.post",
        ".post-item",
        ".entry",
        
        # Klasik yapÄ±lar
        "article",
        ".article",
        ".post",
        "[class*='article']",
        "[class*='post']",
        "[class*='story']",
        "[class*='news']"
    ]
    
    best_selectors = {
        "container": "article",
        "title": "h2 a",
        "link": "h2 a", 
        "date": "time",
        "excerpt": "p"
    }
    
    max_containers = 0
    
    # En Ã§ok konteyner bulan selector'Ä± seÃ§ (ama Ã§ok fazla olmasÄ±n)
    for pattern in container_patterns:
        containers = soup.select(pattern)
        container_count = len(containers)
        
        # Ä°deal aralÄ±k: 3-50 konteyner
        if 3 <= container_count <= 50 and container_count > max_containers:
            max_containers = container_count
            best_selectors["container"] = pattern
            
            # Bu konteyner iÃ§in en iyi title selector'Ä±nÄ± bul
            if containers:
                sample_container = containers[0]
                
                title_patterns = [
                    "h3.loop-card__title a",  # TechCrunch modern
                    "h2 a", "h3 a", "h1 a",
                    ".title a", ".headline a",
                    "[class*='title'] a",
                    "[class*='headline'] a",
                    "a[href*='article']",
                    "a[href*='post']",
                    "a"  # Son Ã§are
                ]
                
                for title_pattern in title_patterns:
                    title_elem = sample_container.select_one(title_pattern)
                    if title_elem and title_elem.get_text(strip=True):
                        best_selectors["title"] = title_pattern
                        best_selectors["link"] = title_pattern
                        break
                
                # Date selector
                date_patterns = [
                    "time.loop-card__time",
                    "time", ".date", ".published",
                    "[class*='date']", "[class*='time']",
                    "[datetime]"
                ]
                
                for date_pattern in date_patterns:
                    if sample_container.select_one(date_pattern):
                        best_selectors["date"] = date_pattern
                        break
    
    return best_selectors, max_containers

def validate_selectors(soup, selectors):
    """Selector'larÄ±n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol et"""
    
    container_selector = selectors.get("container", "article")
    containers = soup.select(container_selector)
    
    if not containers:
        return False, "Konteyner bulunamadÄ±"
    
    if len(containers) > 100:
        return False, f"Ã‡ok fazla konteyner ({len(containers)}), selector Ã§ok genel"
    
    # Ä°lk konteynerden Ã¶rnek al
    sample_container = containers[0]
    
    title_selector = selectors.get("title", "h2 a")
    title_elem = sample_container.select_one(title_selector)
    
    if not title_elem:
        return False, "BaÅŸlÄ±k elementi bulunamadÄ±"
    
    title_text = title_elem.get_text(strip=True)
    if len(title_text) < 10:
        return False, "BaÅŸlÄ±k Ã§ok kÄ±sa"
    
    # Link kontrolÃ¼
    link_elem = title_elem if title_elem.name == 'a' else title_elem.find('a')
    if not link_elem or not link_elem.get('href'):
        return False, "Link bulunamadÄ±"
    
    return True, f"âœ… {len(containers)} konteyner, Ã¶rnek baÅŸlÄ±k: {title_text[:50]}..."

def fetch_articles_from_single_source(source):
    """Tek bir kaynaktan makale Ã§ek"""
    try:
        url = source["url"]
        selectors = source.get("article_selectors", {})
        source_name = source.get("name", "Bilinmeyen")
        
        # SayfayÄ± Ã§ek
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        articles = []
        
        # EÄŸer selector_type auto_detect ise veya mevcut selector'lar Ã§alÄ±ÅŸmÄ±yorsa
        if source.get('selector_type') == 'auto_detect' or not selectors:
            print(f"ğŸ” {source_name} iÃ§in otomatik selector tespiti yapÄ±lÄ±yor...")
            auto_selectors, container_count = auto_detect_selectors(soup, url)
            
            # Otomatik tespit edilen selector'larÄ± doÄŸrula
            is_valid, validation_msg = validate_selectors(soup, auto_selectors)
            
            if is_valid:
                print(f"âœ… Otomatik tespit baÅŸarÄ±lÄ±: {validation_msg}")
                selectors = auto_selectors
                
                # BaÅŸarÄ±lÄ± selector'larÄ± kaydet
                source["article_selectors"] = auto_selectors
                source["selector_type"] = "auto_detected"
            else:
                print(f"âŒ Otomatik tespit baÅŸarÄ±sÄ±z: {validation_msg}")
                return []
        else:
            # Mevcut selector'larÄ± doÄŸrula
            is_valid, validation_msg = validate_selectors(soup, selectors)
            if not is_valid:
                print(f"âš ï¸ Mevcut selector'lar Ã§alÄ±ÅŸmÄ±yor: {validation_msg}")
                print(f"ğŸ”„ Otomatik tespit deneniyor...")
                
                auto_selectors, container_count = auto_detect_selectors(soup, url)
                is_auto_valid, auto_validation_msg = validate_selectors(soup, auto_selectors)
                
                if is_auto_valid:
                    print(f"âœ… Otomatik tespit ile dÃ¼zeltildi: {auto_validation_msg}")
                    selectors = auto_selectors
                else:
                    print(f"âŒ Otomatik tespit de baÅŸarÄ±sÄ±z: {auto_validation_msg}")
                    return []
        
        # Makale konteynerlerini bul
        container_selector = selectors.get("container", "article, .article, .post")
        containers = soup.select(container_selector)
        
        if not containers:
            # Alternatif selectors dene
            alternative_selectors = [
                "li.wp-block-post",  # TechCrunch modern
                "article[data-testid='story-card']",  # The Verge modern
                ".c-entry-box", ".c-compact-river__entry",  # The Verge classic
                "article", ".post", ".news-item", ".story", 
                ".entry", ".content-item", "[class*='article']",
                "[class*='post']", "[class*='news']", "[class*='loop-card']"
            ]
            
            for alt_selector in alternative_selectors:
                containers = soup.select(alt_selector)
                if containers:
                    print(f"ğŸ”„ Alternatif selector kullanÄ±ldÄ±: {alt_selector}")
                    break
        
        print(f"ğŸ” {source['name']}: {len(containers)} konteyner bulundu")
        
        for container in containers[:5]:  # Ä°lk 5 makale
            try:
                # BaÅŸlÄ±k bul
                title_selector = selectors.get("title", "h1, h2, h3, .title, .headline")
                title_elem = container.select_one(title_selector)
                
                # Alternatif title selector'larÄ± dene
                if not title_elem:
                    alt_title_selectors = [
                        "h3.loop-card__title a",  # TechCrunch modern
                        "h2 a", ".c-entry-box__title a",  # The Verge
                        "h1 a", "h2 a", "h3 a", "h4 a",
                        ".title a", ".headline a", "[class*='title'] a"
                    ]
                    
                    for alt_selector in alt_title_selectors:
                        title_elem = container.select_one(alt_selector)
                        if title_elem:
                            break
                
                if not title_elem:
                    continue
                
                title = title_elem.get_text(strip=True)
                
                # Link bul
                link_elem = title_elem.find('a') if title_elem.name != 'a' else title_elem
                if not link_elem:
                    link_elem = container.select_one('a')
                
                if not link_elem:
                    continue
                
                link = link_elem.get('href', '')
                
                # Relative URL'leri absolute yap
                if link.startswith('/'):
                    from urllib.parse import urljoin
                    link = urljoin(url, link)
                elif not link.startswith('http'):
                    continue
                
                # Ã–zet bul
                excerpt_selector = selectors.get("excerpt", ".excerpt, .summary, p")
                excerpt_elem = container.select_one(excerpt_selector)
                excerpt = excerpt_elem.get_text(strip=True)[:200] if excerpt_elem else ""
                
                # Tarih bul (opsiyonel)
                date_selector = selectors.get("date", "time, .date, .published")
                date_elem = container.select_one(date_selector)
                date_str = date_elem.get_text(strip=True) if date_elem else ""
                
                if title and link:
                    articles.append({
                        "title": title,
                        "url": link,
                        "excerpt": excerpt,
                        "date": date_str,
                        "source": source["name"],
                        "source_id": source["id"],
                        "fetch_date": datetime.now().isoformat(),
                        "is_new": True,
                        "already_posted": False
                    })
                    
            except Exception as e:
                print(f"âš ï¸ Makale parse hatasÄ±: {e}")
                continue
        
        return articles
        
    except Exception as e:
        print(f"âŒ {source.get('name', 'Bilinmeyen')} kaynak hatasÄ±: {e}")
        return []

def get_news_sources_stats():
    """Haber kaynaklarÄ± istatistiklerini al"""
    try:
        config = load_news_sources()
        
        total_sources = len(config["sources"])
        enabled_sources = len([s for s in config["sources"] if s.get("enabled", True)])
        total_articles = sum(s.get("article_count", 0) for s in config["sources"])
        avg_success_rate = sum(s.get("success_rate", 0) for s in config["sources"]) / max(1, total_sources)
        
        return {
            "total_sources": total_sources,
            "enabled_sources": enabled_sources,
            "disabled_sources": total_sources - enabled_sources,
            "total_articles_fetched": total_articles,
            "average_success_rate": round(avg_success_rate, 1),
            "sources": config["sources"],
            "settings": config["settings"]
        }
        
    except Exception as e:
        return {
            "total_sources": 0,
            "enabled_sources": 0,
            "disabled_sources": 0,
            "total_articles_fetched": 0,
            "average_success_rate": 0,
            "sources": [],
            "settings": {},
            "error": str(e)
        }

def update_fetch_articles_function():
    """Ana makale Ã§ekme fonksiyonunu gÃ¼ncelle - Ã¶zel kaynaklarÄ± dahil et"""
    try:
        # Ã–nce Ã¶zel kaynaklardan makale Ã§ek
        custom_articles = fetch_articles_from_custom_sources()
        
        # Sonra mevcut TechCrunch fallback'i Ã§ek (eÄŸer Ã¶zel kaynaklarda TechCrunch yoksa)
        config = load_news_sources()
        has_techcrunch = any("techcrunch" in s.get("url", "").lower() for s in config["sources"] if s.get("enabled", True))
        
        if not has_techcrunch:
            print("ğŸ”„ TechCrunch fallback ekleniyor...")
            fallback_articles = fetch_latest_ai_articles_fallback()
            custom_articles.extend(fallback_articles)
        
        return custom_articles
        
    except Exception as e:
        print(f"âŒ GÃ¼ncellenmiÅŸ makale Ã§ekme hatasÄ±: {e}")
        # Fallback olarak eski fonksiyonu Ã§aÄŸÄ±r
        return fetch_latest_ai_articles_fallback()

# =============================================================================
# GÃœVENLÄ° LOGGING SÄ°STEMÄ°
# =============================================================================

def safe_log(message, level="INFO", sensitive_data=None):
    """GÃ¼venli logging - ÅŸifre ve API anahtarlarÄ±nÄ± gizler"""
    import os
    
    # Sadece debug modunda detaylÄ± log
    debug_mode = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    if not debug_mode and level == "DEBUG":
        return
    
    # MesajÄ± gÃ¼venli hale getir
    safe_message = sanitize_log_message(str(message))
    
    # Hassas verileri gizle
    if sensitive_data:
        for key, value in sensitive_data.items():
            if value and len(str(value)) > 3:
                masked_value = str(value)[:3] + "*" * (len(str(value)) - 3)
                safe_message = safe_message.replace(str(value), masked_value)
    
    # Production'da sadece Ã¶nemli loglarÄ± gÃ¶ster
    if not debug_mode and level not in ["ERROR", "WARNING", "INFO"]:
        return
    
    print(f"[{level}] {safe_message}")

# =============================================================================
# GÃœVENLÄ°K KONTROL FONKSÄ°YONLARI
# =============================================================================

def check_security_configuration():
    """GÃ¼venlik yapÄ±landÄ±rmasÄ±nÄ± kontrol et"""
    import os
    
    security_issues = []
    
    # 1. Debug mode kontrolÃ¼
    debug_mode = os.environ.get('DEBUG', 'False').lower() == 'true'
    flask_env = os.environ.get('FLASK_ENV', 'production')
    
    if debug_mode and flask_env == 'production':
        security_issues.append("âš ï¸ Production'da DEBUG modu aÃ§Ä±k!")
    
    # 2. VarsayÄ±lan ÅŸifre kontrolÃ¼
    password = os.environ.get('SIFRE', 'admin123')
    if password in ['admin123', 'password', '123456', 'admin']:
        security_issues.append("ğŸ”’ VarsayÄ±lan ÅŸifre kullanÄ±lÄ±yor! DeÄŸiÅŸtirin.")
    
    # 3. Secret key kontrolÃ¼
    secret_key = os.environ.get('SECRET_KEY', 'your-secret-key-here')
    if secret_key == 'your-secret-key-here' or len(secret_key) < 32:
        security_issues.append("ğŸ”‘ GÃ¼Ã§lÃ¼ SECRET_KEY kullanÄ±n!")
    
    # 4. API anahtarlarÄ± kontrolÃ¼
    api_keys = [
        'GOOGLE_API_KEY',
        'TWITTER_API_KEY',
        'TWITTER_API_SECRET',
        'TWITTER_ACCESS_TOKEN',
        'TWITTER_ACCESS_TOKEN_SECRET'
    ]
    
    for key in api_keys:
        value = os.environ.get(key, '')
        if value and ('your-' in value.lower() or 'example' in value.lower()):
            security_issues.append(f"ğŸ” {key} Ã¶rnek deÄŸer iÃ§eriyor!")
    
    return {
        "secure": len(security_issues) == 0,
        "issues": security_issues,
        "debug_mode": debug_mode,
        "flask_env": flask_env
    }

def sanitize_log_message(message):
    """Log mesajlarÄ±ndan hassas bilgileri temizle"""
    import re
    
    # API anahtarÄ± pattern'leri
    patterns = [
        r'AIza[0-9A-Za-z-_]{35}',  # Google API Key
        r'sk-[a-zA-Z0-9]{48}',     # OpenAI API Key
        r'[0-9]{10}:[A-Za-z0-9_-]{35}',  # Telegram Bot Token
        r'[A-Za-z0-9]{25}',        # Twitter Bearer Token
        r'[A-Za-z0-9]{15,25}',     # Twitter API Keys
    ]
    
    for pattern in patterns:
        message = re.sub(pattern, '***MASKED***', message)
    
    # Åifre pattern'leri
    password_patterns = [
        r'password["\s]*[:=]["\s]*[^"\s]+',
        r'pass["\s]*[:=]["\s]*[^"\s]+',
        r'token["\s]*[:=]["\s]*[^"\s]+',
        r'key["\s]*[:=]["\s]*[^"\s]+',
    ]
    
    for pattern in password_patterns:
        message = re.sub(pattern, 'password=***MASKED***', message, flags=re.IGNORECASE)
    
    return message

def calculate_text_similarity(text1, text2):
    """Ä°ki metin arasÄ±ndaki benzerlik oranÄ±nÄ± hesapla (0-1 arasÄ±)"""
    if not text1 or not text2:
        return 0.0
    
    # Metinleri normalize et
    text1 = text1.lower().strip()
    text2 = text2.lower().strip()
    
    # Ã‡ok kÄ±sa metinler iÃ§in direkt karÅŸÄ±laÅŸtÄ±rma
    if len(text1) < 10 or len(text2) < 10:
        return 1.0 if text1 == text2 else 0.0
    
    # SequenceMatcher ile benzerlik hesapla
    similarity = SequenceMatcher(None, text1, text2).ratio()
    return similarity

def normalize_title_for_comparison(title):
    """BaÅŸlÄ±ÄŸÄ± karÅŸÄ±laÅŸtÄ±rma iÃ§in normalize et"""
    if not title:
        return ""
    
    # KÃ¼Ã§Ã¼k harfe Ã§evir
    normalized = title.lower()
    
    # Gereksiz karakterleri kaldÄ±r
    normalized = re.sub(r'[^\w\s]', ' ', normalized)
    
    # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
    normalized = re.sub(r'\s+', ' ', normalized).strip()
    
    # YaygÄ±n kelimeler ve ifadeleri kaldÄ±r
    stop_words = ['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'says', 'announces', 'reveals', 'launches', 'introduces']
    words = normalized.split()
    filtered_words = [word for word in words if word not in stop_words and len(word) > 2]
    
    return ' '.join(filtered_words)

def extract_key_content_features(content):
    """Ä°Ã§erikten anahtar Ã¶zellikler Ã§Ä±kar"""
    if not content:
        return set()
    
    # Metni normalize et
    normalized = content.lower()
    
    # SayÄ±larÄ± ve Ã¶zel terimleri Ã§Ä±kar
    features = set()
    
    # SayÄ±sal deÄŸerler (para, yÃ¼zde, sayÄ±lar)
    numbers = re.findall(r'\$[\d,]+(?:\.\d+)?[bmk]?|\d+(?:\.\d+)?%|\d+(?:\.\d+)?(?:\s*(?:billion|million|thousand|percent))?', normalized)
    features.update(numbers)
    
    # Åirket isimleri (bÃ¼yÃ¼k harfle baÅŸlayan kelimeler)
    companies = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', content)
    features.update([c.lower() for c in companies])
    
    # Ã–nemli teknoloji terimleri
    tech_terms = re.findall(r'\b(?:ai|artificial intelligence|machine learning|deep learning|neural network|algorithm|api|cloud|blockchain|cryptocurrency|robot|automation|quantum|5g|iot|ar|vr|metaverse)\b', normalized)
    features.update(tech_terms)
    
    return features

def check_content_similarity(article1, article2, title_threshold=0.8, content_threshold=0.6):
    """Ä°ki makale arasÄ±ndaki benzerliÄŸi kontrol et"""
    try:
        title1 = article1.get('title', '')
        title2 = article2.get('title', '')
        content1 = article1.get('content', '')
        content2 = article2.get('content', '')
        
        # BaÅŸlÄ±k benzerliÄŸi
        normalized_title1 = normalize_title_for_comparison(title1)
        normalized_title2 = normalize_title_for_comparison(title2)
        title_similarity = calculate_text_similarity(normalized_title1, normalized_title2)
        
        # EÄŸer baÅŸlÄ±klar Ã§ok benzer ise, muhtemelen aynÄ± haber
        if title_similarity >= title_threshold:
            return True, title_similarity, "title"
        
        # Ä°Ã§erik Ã¶zellik benzerliÄŸi
        features1 = extract_key_content_features(content1)
        features2 = extract_key_content_features(content2)
        
        if features1 and features2:
            # Jaccard benzerliÄŸi (kesiÅŸim / birleÅŸim)
            intersection = len(features1.intersection(features2))
            union = len(features1.union(features2))
            feature_similarity = intersection / union if union > 0 else 0.0
            
            if feature_similarity >= content_threshold:
                return True, feature_similarity, "content_features"
        
        # Ä°Ã§erik metni benzerliÄŸi (sadece kÄ±sa iÃ§erikler iÃ§in)
        if len(content1) < 1000 and len(content2) < 1000:
            content_similarity = calculate_text_similarity(content1[:500], content2[:500])
            if content_similarity >= content_threshold:
                return True, content_similarity, "content_text"
        
        return False, max(title_similarity, feature_similarity if 'feature_similarity' in locals() else 0), "no_match"
        
    except Exception as e:
        print(f"Benzerlik kontrolÃ¼ hatasÄ±: {e}")
        return False, 0.0, "error"

def filter_duplicate_articles(new_articles, existing_articles=None):
    """Yeni makalelerden duplikatlarÄ± filtrele"""
    try:
        # AyarlarÄ± yÃ¼kle
        settings = load_automation_settings()
        
        # EÄŸer duplikat tespiti kapalÄ±ysa, sadece temel kontrolleri yap
        if not settings.get('enable_duplicate_detection', True):
            print("ğŸ”„ GeliÅŸmiÅŸ duplikat tespiti kapalÄ±, sadece temel kontroller yapÄ±lÄ±yor...")
            return basic_duplicate_filter(new_articles, existing_articles)
        
        # EÅŸik deÄŸerlerini ayarlardan al
        title_threshold = settings.get('title_similarity_threshold', 0.8)
        content_threshold = settings.get('content_similarity_threshold', 0.6)
        
        print(f"ğŸ” GeliÅŸmiÅŸ duplikat tespiti aktif (BaÅŸlÄ±k: {title_threshold:.0%}, Ä°Ã§erik: {content_threshold:.0%})")
        
        if existing_articles is None:
            # Mevcut paylaÅŸÄ±lan makaleleri yÃ¼kle
            existing_articles = load_json(HISTORY_FILE)
        
        # Bekleyen tweet'leri de kontrol et
        pending_tweets = load_json("pending_tweets.json")
        pending_articles = [tweet.get('article', {}) for tweet in pending_tweets if tweet.get('article')]
        
        # TÃ¼m mevcut makaleleri birleÅŸtir (silinen makaleler de dahil)
        all_existing = existing_articles + pending_articles
        
        # Silinen makaleleri de kontrol et (deleted=True olanlar)
        deleted_articles = [article for article in existing_articles if article.get('deleted', False)]
        if deleted_articles:
            print(f"ğŸ—‘ï¸ {len(deleted_articles)} silinen makale duplikat kontrole dahil edildi")
        
        filtered_articles = []
        duplicate_count = 0
        
        for new_article in new_articles:
            is_duplicate = False
            
            # Ã–nce URL kontrolÃ¼ (hÄ±zlÄ±)
            new_url = new_article.get('url', '')
            for existing in all_existing:
                if new_url == existing.get('url', ''):
                    is_duplicate = True
                    break
            
            if is_duplicate:
                duplicate_count += 1
                print(f"ğŸ”„ URL duplikatÄ± atlandÄ±: {new_article.get('title', '')[:50]}...")
                continue
            
            # Hash kontrolÃ¼ (hÄ±zlÄ±)
            new_hash = new_article.get('hash', '')
            if new_hash:
                for existing in all_existing:
                    if new_hash == existing.get('hash', ''):
                        is_duplicate = True
                        break
            
            if is_duplicate:
                duplicate_count += 1
                print(f"ğŸ”„ Hash duplikatÄ± atlandÄ±: {new_article.get('title', '')[:50]}...")
                continue
            
            # Ä°Ã§erik benzerliÄŸi kontrolÃ¼ (yavaÅŸ ama etkili)
            for existing in all_existing:
                is_similar, similarity_score, match_type = check_content_similarity(
                    new_article, existing, title_threshold, content_threshold
                )
                if is_similar:
                    is_duplicate = True
                    print(f"ğŸ”„ Ä°Ã§erik benzerliÄŸi ({match_type}: {similarity_score:.2f}) - atlandÄ±: {new_article.get('title', '')[:50]}...")
                    break
            
            if not is_duplicate:
                # AynÄ± batch iÃ§inde de kontrol et
                for other_article in filtered_articles:
                    is_similar, similarity_score, match_type = check_content_similarity(
                        new_article, other_article, title_threshold, content_threshold
                    )
                    if is_similar:
                        is_duplicate = True
                        print(f"ğŸ”„ Batch iÃ§i benzerlik ({match_type}: {similarity_score:.2f}) - atlandÄ±: {new_article.get('title', '')[:50]}...")
                        break
            
            if not is_duplicate:
                filtered_articles.append(new_article)
                print(f"âœ… Yeni makale eklendi: {new_article.get('title', '')[:50]}...")
            else:
                duplicate_count += 1
        
        print(f"ğŸ“Š Duplikat filtreleme tamamlandÄ±: {len(new_articles)} makale â†’ {len(filtered_articles)} benzersiz makale ({duplicate_count} duplikat)")
        return filtered_articles
        
    except Exception as e:
        print(f"Duplikat filtreleme hatasÄ±: {e}")
        return new_articles  # Hata durumunda orijinal listeyi dÃ¶ndÃ¼r

def basic_duplicate_filter(new_articles, existing_articles=None):
    """Temel duplikat filtreleme - sadece URL ve hash kontrolÃ¼"""
    try:
        if existing_articles is None:
            existing_articles = load_json(HISTORY_FILE)
        
        # Bekleyen tweet'leri de kontrol et
        pending_tweets = load_json("pending_tweets.json")
        pending_articles = [tweet.get('article', {}) for tweet in pending_tweets if tweet.get('article')]
        
        # TÃ¼m mevcut makaleleri birleÅŸtir (silinen makaleler de dahil)
        all_existing = existing_articles + pending_articles
        
        # Silinen makaleleri de kontrol et (deleted=True olanlar)
        deleted_articles = [article for article in existing_articles if article.get('deleted', False)]
        if deleted_articles:
            print(f"ğŸ—‘ï¸ {len(deleted_articles)} silinen makale temel duplikat kontrole dahil edildi")
        
        # Mevcut URL'ler ve hash'ler
        existing_urls = set(article.get('url', '') for article in all_existing)
        existing_hashes = set(article.get('hash', '') for article in all_existing)
        
        filtered_articles = []
        duplicate_count = 0
        
        for new_article in new_articles:
            new_url = new_article.get('url', '')
            new_hash = new_article.get('hash', '')
            
            # URL kontrolÃ¼
            if new_url in existing_urls:
                duplicate_count += 1
                print(f"ğŸ”„ URL duplikatÄ± atlandÄ±: {new_article.get('title', '')[:50]}...")
                continue
            
            # Hash kontrolÃ¼
            if new_hash and new_hash in existing_hashes:
                duplicate_count += 1
                print(f"ğŸ”„ Hash duplikatÄ± atlandÄ±: {new_article.get('title', '')[:50]}...")
                continue
            
            # AynÄ± batch iÃ§inde URL kontrolÃ¼
            batch_urls = set(article.get('url', '') for article in filtered_articles)
            if new_url in batch_urls:
                duplicate_count += 1
                print(f"ğŸ”„ Batch iÃ§i URL duplikatÄ± atlandÄ±: {new_article.get('title', '')[:50]}...")
                continue
            
            filtered_articles.append(new_article)
            print(f"âœ… Yeni makale eklendi: {new_article.get('title', '')[:50]}...")
        
        print(f"ğŸ“Š Temel duplikat filtreleme tamamlandÄ±: {len(new_articles)} makale â†’ {len(filtered_articles)} benzersiz makale ({duplicate_count} duplikat)")
        return filtered_articles
        
    except Exception as e:
        print(f"Temel duplikat filtreleme hatasÄ±: {e}")
        return new_articles

def clean_duplicate_pending_tweets():
    """Bekleyen tweet'lerdeki duplikatlarÄ± temizle"""
    try:
        pending_tweets = load_json("pending_tweets.json")
        
        if not pending_tweets:
            return {
                "success": True,
                "message": "Bekleyen tweet bulunamadÄ±",
                "original_count": 0,
                "cleaned_count": 0,
                "removed_count": 0
            }
        
        print(f"ğŸ” {len(pending_tweets)} bekleyen tweet kontrol ediliyor...")
        
        # Benzersiz tweet'leri saklamak iÃ§in
        unique_tweets = []
        seen_urls = set()
        seen_hashes = set()
        seen_titles = set()
        
        duplicate_count = 0
        
        for tweet in pending_tweets:
            article = tweet.get('article', {})
            url = article.get('url', '')
            hash_val = article.get('hash', '')
            title = article.get('title', '')
            
            # URL kontrolÃ¼
            if url and url in seen_urls:
                duplicate_count += 1
                print(f"ğŸ”„ URL duplikatÄ± atlandÄ±: {title[:50]}...")
                continue
            
            # Hash kontrolÃ¼
            if hash_val and hash_val in seen_hashes:
                duplicate_count += 1
                print(f"ğŸ”„ Hash duplikatÄ± atlandÄ±: {title[:50]}...")
                continue
            
            # BaÅŸlÄ±k kontrolÃ¼ (normalize edilmiÅŸ)
            if title:
                normalized_title = normalize_title_for_comparison(title)
                if normalized_title in seen_titles:
                    duplicate_count += 1
                    print(f"ğŸ”„ BaÅŸlÄ±k duplikatÄ± atlandÄ±: {title[:50]}...")
                    continue
                seen_titles.add(normalized_title)
            
            # Benzersiz tweet olarak ekle
            unique_tweets.append(tweet)
            if url:
                seen_urls.add(url)
            if hash_val:
                seen_hashes.add(hash_val)
            
            print(f"âœ… Benzersiz tweet korundu: {title[:50]}...")
        
        # TemizlenmiÅŸ listeyi kaydet
        save_json("pending_tweets.json", unique_tweets)
        
        result = {
            "success": True,
            "message": f"âœ… Bekleyen tweet'ler temizlendi",
            "original_count": len(pending_tweets),
            "cleaned_count": len(unique_tweets),
            "removed_count": duplicate_count
        }
        
        print(f"ğŸ“Š Duplikat temizleme tamamlandÄ±: {len(pending_tweets)} â†’ {len(unique_tweets)} tweet ({duplicate_count} duplikat kaldÄ±rÄ±ldÄ±)")
        
        return result
        
    except Exception as e:
        print(f"âŒ Duplikat temizleme hatasÄ±: {e}")
        return {
            "success": False,
            "message": f"âŒ Temizleme hatasÄ±: {str(e)}",
            "original_count": 0,
            "cleaned_count": 0,
            "removed_count": 0
        }

# =============================================================================
# Rate limit yÃ¶netimi iÃ§in global deÄŸiÅŸkenler
RATE_LIMIT_FILE = "rate_limit_status.json"
TWITTER_RATE_LIMITS = {
    "tweets": {"limit": 5, "window": 900},  # 15 dakikada 5 tweet (Free plan iÃ§in gÃ¼venli)
    "user_lookup": {"limit": 50, "window": 900},  # 15 dakikada 50 kullanÄ±cÄ± sorgusu
    "timeline": {"limit": 30, "window": 900}  # 15 dakikada 30 timeline sorgusu
}

def load_rate_limit_status():
    """Rate limit durumunu yÃ¼kle"""
    try:
        if os.path.exists(RATE_LIMIT_FILE):
            with open(RATE_LIMIT_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except Exception as e:
        print(f"Rate limit durumu yÃ¼klenirken hata: {e}")
        return {}

def save_rate_limit_status(status):
    """Rate limit durumunu kaydet"""
    try:
        with open(RATE_LIMIT_FILE, 'w', encoding='utf-8') as f:
            json.dump(status, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"Rate limit durumu kaydedilirken hata: {e}")

def check_rate_limit(endpoint="tweets"):
    """Rate limit kontrolÃ¼ yap"""
    try:
        status = load_rate_limit_status()
        current_time = time.time()
        
        if endpoint not in status:
            status[endpoint] = {
                "requests": 0,
                "reset_time": current_time + TWITTER_RATE_LIMITS[endpoint]["window"],
                "last_request": current_time
            }
        
        endpoint_status = status[endpoint]
        
        # Reset zamanÄ± geÃ§tiyse sÄ±fÄ±rla
        if current_time >= endpoint_status["reset_time"]:
            endpoint_status["requests"] = 0
            endpoint_status["reset_time"] = current_time + TWITTER_RATE_LIMITS[endpoint]["window"]
        
        # Limit kontrolÃ¼
        if endpoint_status["requests"] >= TWITTER_RATE_LIMITS[endpoint]["limit"]:
            wait_time = endpoint_status["reset_time"] - current_time
            return {
                "allowed": False,
                "wait_time": wait_time,
                "requests_made": endpoint_status["requests"],
                "limit": TWITTER_RATE_LIMITS[endpoint]["limit"]
            }
        
        return {
            "allowed": True,
            "requests_made": endpoint_status["requests"],
            "limit": TWITTER_RATE_LIMITS[endpoint]["limit"],
            "reset_time": endpoint_status["reset_time"]
        }
        
    except Exception as e:
        print(f"Rate limit kontrolÃ¼ hatasÄ±: {e}")
        return {"allowed": True}  # Hata durumunda izin ver

def update_rate_limit_usage(endpoint="tweets"):
    """Rate limit kullanÄ±mÄ±nÄ± gÃ¼ncelle"""
    try:
        status = load_rate_limit_status()
        current_time = time.time()
        
        if endpoint not in status:
            status[endpoint] = {
                "requests": 0,
                "reset_time": current_time + TWITTER_RATE_LIMITS[endpoint]["window"],
                "last_request": current_time
            }
        
        # Reset zamanÄ± geÃ§tiyse sÄ±fÄ±rla
        if current_time >= status[endpoint]["reset_time"]:
            status[endpoint]["requests"] = 0
            status[endpoint]["reset_time"] = current_time + TWITTER_RATE_LIMITS[endpoint]["window"]
        
        # KullanÄ±mÄ± artÄ±r
        status[endpoint]["requests"] += 1
        status[endpoint]["last_request"] = current_time
        
        save_rate_limit_status(status)
        
        print(f"Rate limit gÃ¼ncellendi - {endpoint}: {status[endpoint]['requests']}/{TWITTER_RATE_LIMITS[endpoint]['limit']}")
        
    except Exception as e:
        print(f"Rate limit gÃ¼ncelleme hatasÄ±: {e}")

def get_rate_limit_info():
    """Rate limit bilgilerini al"""
    try:
        status = load_rate_limit_status()
        current_time = time.time()
        info = {}
        
        for endpoint in TWITTER_RATE_LIMITS:
            if endpoint in status:
                endpoint_status = status[endpoint]
                
                # Reset zamanÄ± geÃ§tiyse sÄ±fÄ±rla
                if current_time >= endpoint_status["reset_time"]:
                    requests_made = 0
                    reset_time = current_time + TWITTER_RATE_LIMITS[endpoint]["window"]
                else:
                    requests_made = endpoint_status["requests"]
                    reset_time = endpoint_status["reset_time"]
                
                info[endpoint] = {
                    "requests_made": requests_made,
                    "limit": TWITTER_RATE_LIMITS[endpoint]["limit"],
                    "remaining": TWITTER_RATE_LIMITS[endpoint]["limit"] - requests_made,
                    "reset_time": reset_time,
                    "reset_in_minutes": max(0, (reset_time - current_time) / 60)
                }
            else:
                info[endpoint] = {
                    "requests_made": 0,
                    "limit": TWITTER_RATE_LIMITS[endpoint]["limit"],
                    "remaining": TWITTER_RATE_LIMITS[endpoint]["limit"],
                    "reset_time": current_time + TWITTER_RATE_LIMITS[endpoint]["window"],
                    "reset_in_minutes": TWITTER_RATE_LIMITS[endpoint]["window"] / 60
                }
        
        return info
        
    except Exception as e:
        print(f"Rate limit bilgisi alma hatasÄ±: {e}")
        return {}

def retry_pending_tweets_after_rate_limit():
    """Rate limit sÄ±fÄ±rlandÄ±ktan sonra bekleyen tweet'leri tekrar dene"""
    try:
        # Rate limit durumunu kontrol et
        rate_check = check_rate_limit("tweets")
        if not rate_check.get("allowed", True):
            print(f"Rate limit hala aktif, {int(rate_check.get('wait_time', 0) / 60)} dakika daha beklenecek")
            return {"success": False, "message": "Rate limit hala aktif"}
        
        # Bekleyen tweet'leri yÃ¼kle
        pending_tweets = load_json("pending_tweets.json")
        if not pending_tweets:
            return {"success": True, "message": "Bekleyen tweet yok"}
        
        # Rate limit hatasÄ± olan tweet'leri filtrele
        rate_limited_tweets = []
        other_tweets = []
        
        for tweet in pending_tweets:
            error_reason = tweet.get('error_reason', '')
            if 'rate limit' in error_reason.lower() or '429' in error_reason:
                rate_limited_tweets.append(tweet)
            else:
                other_tweets.append(tweet)
        
        if not rate_limited_tweets:
            return {"success": True, "message": "Rate limit hatasÄ± olan tweet yok"}
        
        print(f"ğŸ”„ {len(rate_limited_tweets)} rate limit hatasÄ± olan tweet tekrar deneniyor...")
        
        successful_posts = 0
        failed_posts = 0
        
        for tweet in rate_limited_tweets:
            try:
                # Rate limit kontrolÃ¼ yap (her tweet iÃ§in)
                rate_check = check_rate_limit("tweets")
                if not rate_check.get("allowed", True):
                    print("Rate limit tekrar aÅŸÄ±ldÄ±, kalan tweet'ler beklemede kalacak")
                    break
                
                # Tweet'i paylaÅŸ
                tweet_text = tweet['tweet_data']['tweet']
                result = post_text_tweet_v2(tweet_text)
                
                if result.get('success'):
                    # BaÅŸarÄ±lÄ± paylaÅŸÄ±m - posted_articles'a ekle
                    article = tweet['article']
                    article['posted_date'] = datetime.now().isoformat()
                    article['tweet_text'] = tweet_text
                    article['tweet_url'] = result.get('url', '')
                    article['manual_post'] = False
                    
                    # Posted articles'a ekle
                    posted_articles = load_json("posted_articles.json")
                    posted_articles.append(article)
                    save_json("posted_articles.json", posted_articles)
                    
                    successful_posts += 1
                    print(f"âœ… Tweet baÅŸarÄ±yla paylaÅŸÄ±ldÄ±: {article.get('title', '')[:50]}...")
                    
                else:
                    # Hala hata var - tweet'i other_tweets'e ekle
                    tweet['retry_count'] = tweet.get('retry_count', 0) + 1
                    tweet['error_reason'] = result.get('error', 'Bilinmeyen hata')
                    other_tweets.append(tweet)
                    failed_posts += 1
                    print(f"âŒ Tweet paylaÅŸÄ±m hatasÄ±: {result.get('error', 'Bilinmeyen hata')}")
                    
                    # Rate limit hatasÄ± ise dur
                    if result.get('rate_limited'):
                        print("Rate limit tekrar aÅŸÄ±ldÄ±, kalan tweet'ler beklemede kalacak")
                        # Kalan tweet'leri de other_tweets'e ekle
                        remaining_tweets = rate_limited_tweets[rate_limited_tweets.index(tweet) + 1:]
                        other_tweets.extend(remaining_tweets)
                        break
                
            except Exception as e:
                print(f"Tweet retry hatasÄ±: {e}")
                tweet['retry_count'] = tweet.get('retry_count', 0) + 1
                tweet['error_reason'] = str(e)
                other_tweets.append(tweet)
                failed_posts += 1
        
        # GÃ¼ncellenmiÅŸ pending tweet'leri kaydet
        save_json("pending_tweets.json", other_tweets)
        
        message = f"âœ… {successful_posts} tweet baÅŸarÄ±yla paylaÅŸÄ±ldÄ±"
        if failed_posts > 0:
            message += f", {failed_posts} tweet hala beklemede"
        
        print(f"ğŸ“Š Retry tamamlandÄ±: {successful_posts} baÅŸarÄ±lÄ±, {failed_posts} baÅŸarÄ±sÄ±z")
        
        return {
            "success": True,
            "message": message,
            "successful_posts": successful_posts,
            "failed_posts": failed_posts
        }
        
    except Exception as e:
        print(f"âŒ Retry iÅŸlemi hatasÄ±: {e}")
        return {"success": False, "message": str(e)}

# ... existing code ...

def terminal_log(message, level='info'):
    """Global terminal log fonksiyonu - app.py'dan import edilebilir"""
    try:
        # app.py'dan TerminalLogHandler'Ä± import etmeye Ã§alÄ±ÅŸ
        from app import log_handler
        if log_handler:
            log_handler.broadcast_log(message, level)
        else:
            print(f"[{level.upper()}] {message}")
    except ImportError:
        # app.py import edilemezse normal print kullan
        print(f"[{level.upper()}] {message}")
    except Exception as e:
        # Herhangi bir hata durumunda normal print kullan
        print(f"[{level.upper()}] {message}")
